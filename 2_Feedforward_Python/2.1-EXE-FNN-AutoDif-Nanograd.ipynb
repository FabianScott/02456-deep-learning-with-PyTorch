{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAva8TnYFtFu"
   },
   "source": [
    "# Contents and why we need this lab\n",
    "\n",
    "This lab is about implementing neural networks yourself before we start using other frameworks that hide some of the computation from you. It builds on the first lab, where you derived the equations for neural network forward and backward propagation and gradient descent parameter updates. \n",
    "\n",
    "All the frameworks for deep learning you will meet from now on use automatic differentiation (autodiff), so you do not have to code the backward step yourself. In this version of this lab, you will develop your own autodif implementation. We also have an optional [version](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/2_Feedforward_Python/2.2-FNN-NumPy.ipynb) of this lab where you have to code the backward pass explicitly in Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCa7HzwpFtFy"
   },
   "source": [
    "# External sources of information\n",
    "\n",
    "1. Jupyter notebook. You can find more information about Jupyter notebooks [here](https://jupyter.org/). It will come as part of the [Anaconda](https://www.anaconda.com/) Python installation. \n",
    "2. [NumPy](https://numpy.org/). Part of Anaconda distribution.  If you already know how to program, most things about Python and NumPy can be found with Google searches.\n",
    "3. [Nanograd](https://github.com/rasmusbergpalm/nanograd) is a minimalistic version of autodiff developed by Rasmus Berg Palm that we use for our framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SjiIp-TFtF0"
   },
   "source": [
    "# This notebook will follow the next steps:\n",
    "\n",
    "1. Nanograd automatic differentiation framework\n",
    "2. Finite difference method\n",
    "3. Data generation\n",
    "4. Defining and initializing the network\n",
    "5. Forward pass\n",
    "6. Training loop \n",
    "7. Testing your model\n",
    "8. Further extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXeAA-HuT7s"
   },
   "source": [
    "# Nanograd automatic differention framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6UWKCLKubgA"
   },
   "source": [
    "The [Nanograd](https://github.com/rasmusbergpalm/nanograd) framework defines a class Var which both holds a value and gradient value that we can use to store the intermediate values when we apply the chain rule of differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jd4CoEBNzNWS"
   },
   "outputs": [],
   "source": [
    "# Copy and pasted from https://github.com/rasmusbergpalm/nanograd/blob/3a1bf9e9e724da813bfccf91a6f309abdade9f39/nanograd.py\n",
    "\n",
    "from math import exp, log, tanh\n",
    "\n",
    "class Var:\n",
    "    \"\"\"\n",
    "    A variable which holds a float and enables gradient computations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, val: float, grad_fn=lambda: []):\n",
    "        assert type(val) == float\n",
    "        self.v = val\n",
    "        self.grad_fn = grad_fn\n",
    "        self.grad = 0.0\n",
    "\n",
    "    def backprop(self, bp):\n",
    "        self.grad += bp\n",
    "        for input, grad in self.grad_fn():\n",
    "            input.backprop(grad * bp)\n",
    "\n",
    "    def backward(self):\n",
    "        self.backprop(1.0)\n",
    "\n",
    "    def __add__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return Var(self.v + other.v, lambda: [(self, 1.0), (other, 1.0)])\n",
    "\n",
    "    def __mul__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return Var(self.v * other.v, lambda: [(self, other.v), (other, self.v)])\n",
    "\n",
    "    def __pow__(self, power):\n",
    "        assert type(power) in {float, int}, \"power must be float or int\"\n",
    "        return Var(self.v ** power, lambda: [(self, power * self.v ** (power - 1))])\n",
    "\n",
    "    def __neg__(self: 'Var') -> 'Var':\n",
    "        return Var(-1.0) * self\n",
    "\n",
    "    def __sub__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return self + (-other)\n",
    "\n",
    "    def __truediv__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return self * other ** -1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Var(v=%.4f, grad=%.4f)\" % (self.v, self.grad)\n",
    "\n",
    "    def relu(self):\n",
    "        return Var(self.v if self.v > 0.0 else 0.0, lambda: [(self, 1.0 if self.v > 0.0 else 0.0)])\n",
    "\n",
    "    def identity(self):\n",
    "        return self\n",
    "\n",
    "    def tanh(self):\n",
    "        return Var(tanh(self.v), lambda: [(self, 1- tanh(self.v) ** 2)])\n",
    "\n",
    "    def sigmoid(self):\n",
    "        return Var(1/(1+exp(-self.v)), lambda: [(self, 1/(1+exp(-self.v)) * (1 - 1/(1+exp(-self.v))))])\n",
    "\n",
    "    def exp(self):\n",
    "        return Var(exp(self.v), lambda: [(self, exp(self.v))])\n",
    "\n",
    "    def log(self):\n",
    "        return Var(log(self.v), lambda: [(self, self.v ** -1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDX67D6jzcte"
   },
   "source": [
    "A few examples illustrate how we can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xk6PeLc3zwPT",
    "outputId": "47e431b2-07ba-4cb1-ea21-997769641c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=5.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(3.0)\n",
    "b = Var(5.0)\n",
    "f = a * b\n",
    "\n",
    "f.backward()\n",
    "\n",
    "for v in [a, b, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmKhYgsY0g_o",
    "outputId": "06c1b1df-c33c-40d3-922a-624612a591c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=14.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "Var(v=9.0000, grad=3.0000)\n",
      "Var(v=27.0000, grad=1.0000)\n",
      "Var(v=42.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(3.0)\n",
    "b = Var(5.0)\n",
    "c = a * b\n",
    "d = Var(9.0)\n",
    "e = a * d\n",
    "f = c + e\n",
    "\n",
    "f.backward()\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe3B6uEH140p"
   },
   "source": [
    "## Exercise a) What is being calculated?\n",
    "\n",
    "Explain briefly the output of the code? What is the expression we differentiate and with respect to what variables?\n",
    "The chain rule of differentiation in applied to f, meaning every composite part of f also has its gradient calculated. These gradients are also stored in their respective variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8_Q0t2I3Ruj"
   },
   "source": [
    "## Exercise b) How does the backward function work?\n",
    "\n",
    "You need to understand how the backward function calculates the gradients. We can use the two examples above to help with that.\n",
    "\n",
    "Go through the following four steps and answer the questions on the way:\n",
    "\n",
    "1. We represent the two expressions as graphs as shown below. Fill in the missing expressions for the different derivatives.\n",
    "\n",
    "2. In the remainder consider the first expression. Make a schematic of the data structure which is generated when we define the expression for f. \n",
    "\n",
    "3. Then execute the backward function by hand to convince yourself that it indeed calculates the gradients with respect to the variables. \n",
    "\n",
    "4. Write down the sequence of calls to backprop.\n",
    "\n",
    "The gradient for f is calculated using backprop(1), thus resulting in 1.\n",
    "Next the backprop is calculated for c and e, again with backprop(1) due\n",
    "to them being added in the composition of f. Next a has backprop(b) as its\n",
    "grad is b due to the multiplication to create c. b has backprop(a). The same\n",
    "pattern repeats for d. Then for a again, it is called with backprop(d),\n",
    "resulting in the gradient c + d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "idGr71jYXl26"
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "import graphviz\n",
    "\n",
    "#logging.basicConfig(format='[%(levelname)s@%(name)s] %(message)s', level=logging.DEBUG)\n",
    "\n",
    "#graphviz.__version__, graphviz.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "KPe30Q2QXzeG",
    "outputId": "7fa002cd-a018-4dbb-ddf1-28ed5e99ee19"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n -->\n<!-- Title: first expression Pages: 1 -->\n<svg width=\"161pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 161.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>first expression</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 157,-94 157,4 -4,4\"/>\n<!-- a -->\n<g id=\"node1\" class=\"node\">\n<title>a</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-72\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-66.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- f -->\n<g id=\"node2\" class=\"node\">\n<title>f</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"135\" cy=\"-45\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"135\" y=\"-39.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\n</g>\n<!-- a&#45;&gt;f -->\n<g id=\"edge1\" class=\"edge\">\n<title>a&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.97,-68.02C54.48,-63.67 84.41,-56.64 106.33,-51.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107.03,-54.69 115.96,-49 105.43,-47.88 107.03,-54.69\"/>\n<text text-anchor=\"middle\" x=\"76.5\" y=\"-65.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">df/da=b</text>\n</g>\n<!-- b -->\n<g id=\"node3\" class=\"node\">\n<title>b</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n</g>\n<!-- b&#45;&gt;f -->\n<g id=\"edge2\" class=\"edge\">\n<title>b&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.96,-20.95C52.23,-23.89 77.44,-28.76 99,-34.25 101.64,-34.92 104.38,-35.67 107.11,-36.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"105.78,-40.01 116.36,-39.53 107.79,-33.3 105.78,-40.01\"/>\n<text text-anchor=\"middle\" x=\"76.5\" y=\"-37.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">df/db=a</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x21f261b77c0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = graphviz.Digraph('first expression', filename='fsm.gv')\n",
    "\n",
    "e1.attr(rankdir='LR', size='8,5')\n",
    "\n",
    "e1.attr('node', shape='circle')\n",
    "e1.edge('a', 'f', label='df/da=b')\n",
    "e1.edge('b', 'f', label='df/db=a')\n",
    "\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "0nittR-mZFeX",
    "outputId": "fa3656a3-732c-4abe-8084-98a492b0d6be"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n -->\n<!-- Title: second expression Pages: 1 -->\n<svg width=\"280pt\" height=\"161pt\"\n viewBox=\"0.00 0.00 280.25 161.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 157)\">\n<title>second expression</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-157 276.25,-157 276.25,4 -4,4\"/>\n<!-- a -->\n<g id=\"node1\" class=\"node\">\n<title>a</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-77\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-71.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- c -->\n<g id=\"node2\" class=\"node\">\n<title>c</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.25\" cy=\"-103\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.25\" y=\"-97.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">c</text>\n</g>\n<!-- a&#45;&gt;c -->\n<g id=\"edge1\" class=\"edge\">\n<title>a&#45;&gt;c</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.05,-80.78C55.07,-85 86.11,-91.88 108.61,-96.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107.66,-100.47 118.18,-99.21 109.18,-93.63 107.66,-100.47\"/>\n<text text-anchor=\"middle\" x=\"77.62\" y=\"-96.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dc/da=b</text>\n</g>\n<!-- e -->\n<g id=\"node4\" class=\"node\">\n<title>e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.25\" cy=\"-49\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.25\" y=\"-43.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- a&#45;&gt;e -->\n<g id=\"edge3\" class=\"edge\">\n<title>a&#45;&gt;e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.25,-71.06C41.11,-69.05 47.8,-66.89 54,-65.25 71.89,-60.5 92.29,-56.46 108.31,-53.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"108.84,-56.88 118.09,-51.73 107.64,-49.99 108.84,-56.88\"/>\n<text text-anchor=\"middle\" x=\"77.62\" y=\"-68.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">de/da=d</text>\n</g>\n<!-- f -->\n<g id=\"node6\" class=\"node\">\n<title>f</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"254.25\" cy=\"-75\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"254.25\" y=\"-69.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\n</g>\n<!-- c&#45;&gt;f -->\n<g id=\"edge5\" class=\"edge\">\n<title>c&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.22,-98.87C173.84,-94.33 204,-86.99 225.96,-81.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"226.7,-84.82 235.59,-79.06 225.04,-78.02 226.7,-84.82\"/>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-95.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">df/dc=1</text>\n</g>\n<!-- b -->\n<g id=\"node3\" class=\"node\">\n<title>b</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-135\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-129.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n</g>\n<!-- b&#45;&gt;c -->\n<g id=\"edge2\" class=\"edge\">\n<title>b&#45;&gt;c</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.72,-130.62C52.36,-126.23 78.6,-119.27 101.25,-113 103.77,-112.3 106.39,-111.57 109.01,-110.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.87,-113.94 118.53,-107.84 107.96,-107.21 109.87,-113.94\"/>\n<text text-anchor=\"middle\" x=\"77.62\" y=\"-127.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dc/db=a</text>\n</g>\n<!-- e&#45;&gt;f -->\n<g id=\"edge6\" class=\"edge\">\n<title>e&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.65,-50.54C172.01,-52.25 197.09,-55.55 218.25,-61.25 221.26,-62.06 224.37,-63.05 227.44,-64.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.88,-67.65 236.47,-67.94 228.37,-61.11 225.88,-67.65\"/>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-64.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">df/de=1</text>\n</g>\n<!-- d -->\n<g id=\"node5\" class=\"node\">\n<title>d</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\n</g>\n<!-- d&#45;&gt;e -->\n<g id=\"edge4\" class=\"edge\">\n<title>d&#45;&gt;e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.18,-21.13C52.93,-24.34 79.06,-29.78 101.25,-36.25 104.06,-37.07 106.98,-38 109.87,-38.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"108.42,-42.53 119.02,-42.58 110.77,-35.94 108.42,-42.53\"/>\n<text text-anchor=\"middle\" x=\"77.62\" y=\"-39.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">de/dd=a</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x21f26719fd0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = graphviz.Digraph('second expression', filename='fsm.gv')\n",
    "\n",
    "e2.attr(rankdir='LR', size='8,5')\n",
    "\n",
    "e2.attr('node', shape='circle')\n",
    "e2.edge('a', 'c', label='dc/da=b')\n",
    "e2.edge('b', 'c', label='dc/db=a')\n",
    "e2.edge('a', 'e', label='de/da=d')\n",
    "e2.edge('d', 'e', label='de/dd=a')\n",
    "e2.edge('c', 'f', label='df/dc=1')\n",
    "e2.edge('e', 'f', label='df/de=1')\n",
    "\n",
    "e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5oi21W4gpeM"
   },
   "source": [
    "## Exercise c) What happens if we run backward again?\n",
    "\n",
    "Try to execute the code below. Explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCtpJyr-gyX1",
    "outputId": "d014bcfa-c9ae-49c3-d268-91cc6ca94ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=28.0000)\n",
      "Var(v=5.0000, grad=6.0000)\n",
      "Var(v=15.0000, grad=2.0000)\n",
      "Var(v=9.0000, grad=6.0000)\n",
      "Var(v=27.0000, grad=2.0000)\n",
      "Var(v=42.0000, grad=2.0000)\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The gradients are stored and thus for the initial downstream elements of f the gradients are multiplied by 2 instead of 1, which propagates through the entire system."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8bPVq2VhsP-"
   },
   "source": [
    "## Exercise d) Zero gradient\n",
    "\n",
    "We can zero the gradient by backpropagating a -1.0 as is shown in the example below. (If you have run backward multiple time then you also have to run the cell below an equal amount of times.) Explain what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnyPDQx9lJe0",
    "outputId": "7a125fdc-60c4-4340-a580-8b82aea5b0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=6.0000)\n",
      "Var(v=15.0000, grad=2.0000)\n",
      "Var(v=9.0000, grad=6.0000)\n",
      "Var(v=27.0000, grad=2.0000)\n",
      "Var(v=42.0000, grad=2.0000)\n",
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "Var(v=9.0000, grad=3.0000)\n",
      "Var(v=27.0000, grad=1.0000)\n",
      "Var(v=42.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(2.0)\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)\n",
    "\n",
    "f.backprop(-1.0)\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we again observe the effect of adding/subtracting a value to the initial gradient. As it is used for multiplication of the downstream gradients it will have an effect. The factor from the initial call to backpropagation should be 1 to get the initial results, thus subtracting 1 from 2 = 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4057_ljNvWB"
   },
   "source": [
    "## Exercise e) Test correctness of derivatives with the finite difference method\n",
    "\n",
    "Write a small function that uses [the finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method) to numerically test that backpropation implementation is working. In short we will use\n",
    "$$\n",
    "\\frac{\\partial f(a)}{\\partial a} \\approx \\frac{f(a+da)-f(a)}{da}\n",
    "$$\n",
    "for $da \\ll 1$.\n",
    "\n",
    "As an example, we could approximate the derivative of the function $f(a)=a^2$ in e.g. the value $a=4$ using the finite difference method. This amounts to inserting the relevant values and approximating the gradient $f'(4)$ with the fraction above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TGil92lSXDN",
    "outputId": "7ef5489b-b525-4132-ab08-0b1109c07f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=5.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "4.000000330961484\n"
     ]
    }
   ],
   "source": [
    "# f function - try to change the code to test other types of functions as well (such as different polynomials etc.)\n",
    "def f_function(a):\n",
    "  a = Var(a)\n",
    "  b = Var(5.0)\n",
    "  f = a * b\n",
    "  f.backward()\n",
    "  return a,b,f\n",
    "\n",
    "for v in f_function(3.0):\n",
    "  print(v)\n",
    "\n",
    "# Insert your finite difference code here\n",
    "def finite_difference(da=1e-10):\n",
    "    \"\"\"\n",
    "    This function compute the finite difference between\n",
    "    \n",
    "    Input:\n",
    "    da:          The finite difference                           (float)\n",
    "    \n",
    "    Output:\n",
    "    finite_difference: numerical approximation to the derivative (float) \n",
    "    \"\"\"\n",
    "    \n",
    "    fa_da = (2 + da)**2           # <- Insert correct expression\n",
    "    fa = 2.**2               # <- Insert correct expression\n",
    "\n",
    "    finite_difference = (fa_da - fa) / da\n",
    "    \n",
    "    return finite_difference\n",
    "\n",
    "print(finite_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pZar5RKaUkg"
   },
   "source": [
    "# Create an artificial dataset to play with\n",
    "\n",
    "We create a non-linear 1d regression task. The generator supports various noise levels and it creates train, validation and test sets. You can modify it yourself if you want more or less challenging tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y6yfMAQ8aduj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4YabfD43ajNh"
   },
   "outputs": [],
   "source": [
    "def data_generator(noise=0.2, n_samples=300, D1=True):\n",
    "    # Create covariates and response variable\n",
    "    if D1:\n",
    "        X = np.linspace(-3, 3, num=n_samples).reshape(-1,1) # 1-D\n",
    "        np.random.shuffle(X)\n",
    "        y = np.random.normal((0.5*np.sin(X[:,0]*3) + X[:,0]), noise) # 1-D with trend\n",
    "    else:\n",
    "        X = np.random.multivariate_normal(np.zeros(3), noise*np.eye(3), size = n_samples) # 3-D\n",
    "        np.random.shuffle(X)    \n",
    "        y = np.sin(X[:,0]) - 5*(X[:,1]**2) + 0.5*X[:,2] # 3-D\n",
    "\n",
    "    # Stack them together vertically to split data set\n",
    "    data_set = np.vstack((X.T,y)).T\n",
    "    \n",
    "    train, validation, test = np.split(data_set, [int(0.35*n_samples), int(0.7*n_samples)], axis=0)\n",
    "    \n",
    "    # Standardization of the data, remember we do the standardization with the training set mean and standard deviation\n",
    "    train_mu = np.mean(train, axis=0)\n",
    "    train_sigma = np.std(train, axis=0)\n",
    "    \n",
    "    train = (train-train_mu)/train_sigma\n",
    "    validation = (validation-train_mu)/train_sigma\n",
    "    test = (test-train_mu)/train_sigma\n",
    "    \n",
    "    x_train, x_validation, x_test = train[:,:-1], validation[:,:-1], test[:,:-1]\n",
    "    y_train, y_validation, y_test = train[:,-1], validation[:,-1], test[:,-1]\n",
    "\n",
    "    return x_train, y_train,  x_validation, y_validation, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u1oDngHLapIz"
   },
   "outputs": [],
   "source": [
    "D1 = True\n",
    "x_train, y_train,  x_validation, y_validation, x_test, y_test = data_generator(noise=0.5, D1=D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Ysfa3FsBavlm",
    "outputId": "399e5382-ae7d-48f6-9774-7ea4c73e7d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if D1:\n",
    "    plt.scatter(x_train[:,0], y_train);\n",
    "    plt.scatter(x_validation[:,0], y_validation);\n",
    "    plt.scatter(x_test[:,0], y_test);\n",
    "else:\n",
    "    plt.scatter(x_train[:,1], y_train);\n",
    "    plt.scatter(x_validation[:,1], y_validation);\n",
    "    plt.scatter(x_test[:,1], y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zac2HHNlgbpm"
   },
   "outputs": [],
   "source": [
    "# convert from nparray to Var\n",
    "def nparray_to_Var(x):\n",
    "  if x.ndim==1:\n",
    "    y = [[Var(float(x[i]))] for i in range(x.shape[0])] # always work with list of list\n",
    "  else:\n",
    "    y = [[Var(float(x[i,j])) for j in range(x.shape[1])] for i in range(x.shape[0])]\n",
    "  return y\n",
    "   \n",
    "x_train = nparray_to_Var(x_train)\n",
    "y_train = nparray_to_Var(y_train)\n",
    "x_validation = nparray_to_Var(x_validation)\n",
    "y_validation = nparray_to_Var(y_validation)\n",
    "x_test = nparray_to_Var(x_test)\n",
    "y_test = nparray_to_Var(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbjrqcpVFtGe"
   },
   "source": [
    "# Defining and initializing the network\n",
    "\n",
    "The steps to create a feed forward neural network are the following:\n",
    "\n",
    "1. **Number of hidden layer and hidden units**. We have to define the number of hidden units in each layer. The number of features in X and the output dimensionality (the size of Y) are given but the numbers in between are set by the researcher. Remember that for each unit in each layer beside in the input has a bias term.\n",
    "2. **Activation functions** for each hidden layer. Each hidden layer in your list must have an activation function (it can also be the linear activation which is equivalent to identity function). The power of neural networks comes from non-linear activation functions that learn representations (features) from the data allowing us to learn from it. \n",
    "3. **Parameter initialization**. We will initialize the weights to have random values. This is done in practice by drawing pseudo random numbers from a Gaussian or uniform distribution. It turns out that for deeper models we have to be careful about how we scale the random numbers. This will be the topic of the exercise below. For now we will just use unit variance Gaussians.  \n",
    "\n",
    "In order to make life easier for ourselves we define a DenseLayer class that takes care of initialization and the forward pass. We can also extend it later with print and advanced initialization capabilities. For the latter we have introduced a Initializer class.\n",
    "\n",
    "Note that we use Sequence in the code below. A Sequence is an ordered list. This means the order we insert and access items are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ij_ieRsAt7Xt"
   },
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "\n",
    "  def init_weights(self, n_in, n_out):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def init_bias(self, n_out):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eb18N5phuIha"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NormalInitializer(Initializer):\n",
    "\n",
    "  def __init__(self, mean=0, std=0.1):\n",
    "    self.mean = mean\n",
    "    self.std = std\n",
    "\n",
    "  def init_weights(self, n_in, n_out):\n",
    "    return [[Var(random.gauss(self.mean, self.std)) for _ in range(n_out)] for _ in range(n_in)]\n",
    "\n",
    "  def init_bias(self, n_out):\n",
    "    return [Var(0.0) for _ in range(n_out)]\n",
    "\n",
    "class ConstantInitializer(Initializer):\n",
    "\n",
    "  def __init__(self, weight=1.0, bias=0.0):\n",
    "    self.weight = weight\n",
    "    self.bias = bias\n",
    "\n",
    "  def init_weights(self, n_in, n_out):\n",
    "    return [[Var(self.weight) for _ in range(n_out)] for _ in range(n_in)]\n",
    "\n",
    "  def init_bias(self, n_out):\n",
    "    return [Var(self.bias) for _ in range(n_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jOLYGnZKuM6W"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_in: int, n_out: int, act_fn, initializer = NormalInitializer()):\n",
    "        self.weights = initializer.init_weights(n_in, n_out)\n",
    "        self.bias = initializer.init_bias(n_out)\n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def __repr__(self):    \n",
    "        return 'Weights: ' + repr(self.weights) + ' Biases: ' + repr(self.bias)\n",
    "\n",
    "    def parameters(self) -> Sequence[Var]:\n",
    "      params = []\n",
    "      for r in self.weights:\n",
    "        params += r\n",
    "\n",
    "      return params + self.bias\n",
    "\n",
    "    def forward(self, single_input: Sequence[Var]) -> Sequence[Var]:\n",
    "        # self.weights is a matrix with dimension n_in x n_out. We check that the dimensionality of the input \n",
    "        # to the current layer matches the number of nodes in the current layer\n",
    "        assert len(self.weights) == len(single_input), \"weights and single_input must match in first dimension\"\n",
    "        weights = self.weights\n",
    "        out = []\n",
    "        # For some given data point single_input, we now want to calculate the resulting value in each node in the current layer\n",
    "        # We therefore loop over the (number of) nodes in the current layer:\n",
    "        for j in range(len(weights[0])): \n",
    "            # Initialize the node value depending on its corresponding parameters.\n",
    "            node = weights[0][j] # <- Insert code\n",
    "            # We now finish the linear transformation corresponding to the parameters of the currently considered node.\n",
    "            for i in range(len(single_input)):\n",
    "                node += single_input[i] * weights[i][j] + self.bias[j]  # <- Insert code\n",
    "                # Iterating over the input we must\n",
    "            node = self.act_fn(node)\n",
    "            out.append(node)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpIZPBpNI0pO"
   },
   "source": [
    "## Exercise f) Add more activation functions\n",
    "\n",
    "To have a full definition of the neural network, we must define an activation function for every layer. Several activation functions have been proposed and have different characteristics. In the Var class we have already defined the rectified linear init (relu). \n",
    " \n",
    "Implement the following activation functions in the Var class:\n",
    "\n",
    "* Identity: $$\\mathrm{identity}(x) = x$$\n",
    "* Hyperbolic tangent: $$\\tanh(x)$$\n",
    "* Sigmoid (or logistic function): $$\\mathrm{sigmoid}(x) = \\frac{1}{1.0 + \\exp(-x ) }$$  Hint: $\\mathrm{sigmoid}'(x)= \\mathrm{sigmoid}(x)(1-\\mathrm{sigmoid}(x))$.  \n",
    "\n",
    "Hint: You can seek inspiration in the relu method in the Var class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_8n_SKnIW2F"
   },
   "source": [
    "## Exercise g) Complete the forward pass\n",
    "\n",
    "In the code below we initialize a 1-5-1 network and pass the training set through it. *The forward method in DenseLayer is **not** complete*. It just outputs zeros right now. The method forward should perform an [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) on the input followed by an application of the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "xDEjtePxE7Mv",
    "outputId": "753406cd-d8a1-4282-ce03-25ad959b0e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Var(v=-0.0365, grad=0.0000)], [Var(v=-0.0402, grad=0.0000)], [Var(v=-0.0335, grad=0.0000)], [Var(v=-0.0267, grad=0.0000)], [Var(v=-0.0383, grad=0.0000)], [Var(v=-0.0379, grad=0.0000)], [Var(v=-0.0361, grad=0.0000)], [Var(v=-0.0309, grad=0.0000)], [Var(v=-0.0266, grad=0.0000)], [Var(v=-0.0348, grad=0.0000)], [Var(v=-0.0385, grad=0.0000)], [Var(v=-0.0278, grad=0.0000)], [Var(v=-0.0374, grad=0.0000)], [Var(v=-0.0275, grad=0.0000)], [Var(v=-0.0352, grad=0.0000)], [Var(v=-0.0376, grad=0.0000)], [Var(v=-0.0416, grad=0.0000)], [Var(v=-0.0370, grad=0.0000)], [Var(v=-0.0332, grad=0.0000)], [Var(v=-0.0342, grad=0.0000)], [Var(v=-0.0291, grad=0.0000)], [Var(v=-0.0311, grad=0.0000)], [Var(v=-0.0392, grad=0.0000)], [Var(v=-0.0393, grad=0.0000)], [Var(v=-0.0306, grad=0.0000)], [Var(v=-0.0274, grad=0.0000)], [Var(v=-0.0411, grad=0.0000)], [Var(v=-0.0420, grad=0.0000)], [Var(v=-0.0338, grad=0.0000)], [Var(v=-0.0386, grad=0.0000)], [Var(v=-0.0269, grad=0.0000)], [Var(v=-0.0342, grad=0.0000)], [Var(v=-0.0272, grad=0.0000)], [Var(v=-0.0270, grad=0.0000)], [Var(v=-0.0372, grad=0.0000)], [Var(v=-0.0315, grad=0.0000)], [Var(v=-0.0267, grad=0.0000)], [Var(v=-0.0298, grad=0.0000)], [Var(v=-0.0275, grad=0.0000)], [Var(v=-0.0288, grad=0.0000)], [Var(v=-0.0300, grad=0.0000)], [Var(v=-0.0289, grad=0.0000)], [Var(v=-0.0414, grad=0.0000)], [Var(v=-0.0280, grad=0.0000)], [Var(v=-0.0290, grad=0.0000)], [Var(v=-0.0282, grad=0.0000)], [Var(v=-0.0383, grad=0.0000)], [Var(v=-0.0380, grad=0.0000)], [Var(v=-0.0310, grad=0.0000)], [Var(v=-0.0382, grad=0.0000)], [Var(v=-0.0351, grad=0.0000)], [Var(v=-0.0330, grad=0.0000)], [Var(v=-0.0386, grad=0.0000)], [Var(v=-0.0289, grad=0.0000)], [Var(v=-0.0421, grad=0.0000)], [Var(v=-0.0410, grad=0.0000)], [Var(v=-0.0302, grad=0.0000)], [Var(v=-0.0299, grad=0.0000)], [Var(v=-0.0358, grad=0.0000)], [Var(v=-0.0270, grad=0.0000)], [Var(v=-0.0382, grad=0.0000)], [Var(v=-0.0279, grad=0.0000)], [Var(v=-0.0267, grad=0.0000)], [Var(v=-0.0354, grad=0.0000)], [Var(v=-0.0347, grad=0.0000)], [Var(v=-0.0272, grad=0.0000)], [Var(v=-0.0270, grad=0.0000)], [Var(v=-0.0396, grad=0.0000)], [Var(v=-0.0278, grad=0.0000)], [Var(v=-0.0355, grad=0.0000)], [Var(v=-0.0308, grad=0.0000)], [Var(v=-0.0319, grad=0.0000)], [Var(v=-0.0381, grad=0.0000)], [Var(v=-0.0359, grad=0.0000)], [Var(v=-0.0321, grad=0.0000)], [Var(v=-0.0412, grad=0.0000)], [Var(v=-0.0293, grad=0.0000)], [Var(v=-0.0294, grad=0.0000)], [Var(v=-0.0284, grad=0.0000)], [Var(v=-0.0416, grad=0.0000)], [Var(v=-0.0341, grad=0.0000)], [Var(v=-0.0336, grad=0.0000)], [Var(v=-0.0269, grad=0.0000)], [Var(v=-0.0318, grad=0.0000)], [Var(v=-0.0291, grad=0.0000)], [Var(v=-0.0312, grad=0.0000)], [Var(v=-0.0314, grad=0.0000)], [Var(v=-0.0287, grad=0.0000)], [Var(v=-0.0268, grad=0.0000)], [Var(v=-0.0267, grad=0.0000)], [Var(v=-0.0360, grad=0.0000)], [Var(v=-0.0304, grad=0.0000)], [Var(v=-0.0285, grad=0.0000)], [Var(v=-0.0377, grad=0.0000)], [Var(v=-0.0273, grad=0.0000)], [Var(v=-0.0269, grad=0.0000)], [Var(v=-0.0351, grad=0.0000)], [Var(v=-0.0332, grad=0.0000)], [Var(v=-0.0407, grad=0.0000)], [Var(v=-0.0284, grad=0.0000)], [Var(v=-0.0380, grad=0.0000)], [Var(v=-0.0285, grad=0.0000)], [Var(v=-0.0272, grad=0.0000)], [Var(v=-0.0353, grad=0.0000)], [Var(v=-0.0402, grad=0.0000)]]\n"
     ]
    }
   ],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 5, lambda x: x.relu()),\n",
    "    DenseLayer(5, 1, lambda x: x.identity())\n",
    "]\n",
    "\n",
    "def forward(input, network):\n",
    "\n",
    "  def forward_single(x, network):\n",
    "    for layer in network:\n",
    "        x = layer.forward(x)\n",
    "    return x\n",
    "\n",
    "  output = [ forward_single(input[n], network) for n in range(len(input))]\n",
    "  return output\n",
    "\n",
    "print(forward(x_train, NN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLrGJytZFtGm"
   },
   "source": [
    "## Exercise h) Print all network parameters\n",
    "\n",
    "Make a function that prints all the parameters of the network (weights and biases) with information about in which layer the appear. In the object oriented spirit you should introduce a method in the DenseLayer class to print the parameters of a layer. Hint: You can take inspiration from the corresponding method in Var. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iac-VwYGFtGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[Var(v=-0.0169, grad=0.0000), Var(v=0.0380, grad=0.0000), Var(v=-0.0856, grad=0.0000), Var(v=-0.0062, grad=0.0000), Var(v=-0.0559, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Weights: [[Var(v=-0.0276, grad=0.0000)], [Var(v=-0.1354, grad=0.0000)], [Var(v=0.0798, grad=0.0000)], [Var(v=-0.0559, grad=0.0000)], [Var(v=-0.0757, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n"
     ]
    }
   ],
   "source": [
    "for layer in NN:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_79HOAXrFtHK"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Now that we have defined our activation functions we can visualize them to see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1FcylHqLTl-Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x21f29177310>]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "\n",
    "# convert from Var to ndarray  \n",
    "def Var_to_nparray(x):\n",
    "  y = np.zeros((len(x),len(x[0])))\n",
    "  for i in range(len(x)):\n",
    "    for j in range(len(x[0])):\n",
    "      y[i,j] = x[i][j].v\n",
    "  return y\n",
    "\n",
    "# define 1-1 network with weight = 1 and relu activation \n",
    "NN = [ DenseLayer(1, 1, lambda x: x.relu(), initializer = ConstantInitializer(1.0)) ] \n",
    "y = Var_to_nparray(forward(nparray_to_Var(x), NN))\n",
    "\n",
    "#y = Var_to_nparray(relu(nparray_to_Var(x)))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oOL2UolJFtHL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing all activation layers\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "units = {\n",
    "    \"identity\": lambda x: x.identity(),\n",
    "    \"sigmoid\": lambda x: x.sigmoid(),\n",
    "    \"relu\": lambda x: x.relu(),\n",
    "    \"tanh\": lambda x: x.tanh()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "[plt.plot(x, Var_to_nparray(forward(nparray_to_Var(x), [DenseLayer(1, 1, unit, initializer = ConstantInitializer(1.0))]) ), label=unit_name, lw=2) for unit_name, unit in units.items()] # unit(nparray_to_Var(x))), label=unit_name, lw=2) for unit_name, unit in units.items()]\n",
    "plt.legend(loc=2, fontsize=16)\n",
    "plt.title('Our activation functions', fontsize=20)\n",
    "plt.ylim([-2, 5])\n",
    "plt.xlim([-6, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-jdEl-7FtGs"
   },
   "source": [
    "# Advanced initialization schemes\n",
    "\n",
    "If we are not careful with initialization, the signals we propagate forward ($a^{(l)}$, $l=1,\\ldots,L$) and backward ($\\delta^l$, $l=L,L-1,\\ldots,1$) can blow up or shrink to zero. A statistical analysis of the variance of the signals for different activation functions can be found in these two papers: [Glorot initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) and [He initialization](https://arxiv.org/pdf/1502.01852v1.pdf). \n",
    "\n",
    "The result of the analyses are proposals for how to make the initialization such that the variance of the signals (forward and backward) are kept approxmimatly constant when propagating from layer to layer. The exact expressions depend upon the non-linear activation function used. In Glorot initialization, the aim is to keep both the forward and backward variances constant whereas He only aims at keeping the variance in the forward pass constant.\n",
    "\n",
    "We define $n_{in}$ and $n_{out}$ as the number of input units and output units of a particular layer. \n",
    "\n",
    "The Glorot initialization has the form: \n",
    "\n",
    "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{2 \\alpha }{n_{in} + n_{out}} \\bigg) \\ . $$\n",
    "\n",
    "where $N(\\mu,\\sigma^2)$ is a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$ and $\\alpha$ is a parameter that depends upon the activation function used. For $\\tanh$, $\\alpha=1$ and for Rectified Linear Unit (ReLU) activations, $\\alpha=2$. (It is also possible to use a uniform distribution for initialization, see [this blog post](https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init).) \n",
    "\n",
    "The He initialization is very similar\n",
    "\n",
    "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{\\alpha}{n_{in}} \\bigg) \\ . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqeyab9qFtGs"
   },
   "source": [
    "## Exercise i) Glorot and He initialization\n",
    " \n",
    "Using the Initializer class, implement functions that implement Glorot and He \n",
    "\n",
    "Explain briefly how you would test numerically that these initializations have the sought after property. Hint: See plots in Glorot paper.\n",
    "\n",
    "Comment: If you want to be more advanced then try to make a universal initializer taking both the activation function and type (Glorot or He) as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Qyk01CgaFtGt"
   },
   "outputs": [],
   "source": [
    "## Glorot\n",
    "def DenseLayer_Glorot_tanh(n_in: int, n_out: int):\n",
    "  std = 2 * 1 / (n_in + n_out) # <- replace with proper initialization\n",
    "  return DenseLayer(n_in, n_out, lambda x: x.tanh(), initializer = NormalInitializer(std))\n",
    "\n",
    "## He\n",
    "def DenseLayer_He_relu(n_in: int, n_out: int):\n",
    "  std = 2/n_in # <- replace with proper initialization\n",
    "  return DenseLayer(n_in, n_out, lambda x: x.relu(), initializer = NormalInitializer(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting the activation values of each layer in a histogram to see if they look normally distributed, would reveal whether the initialisation is implemented correctly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XyXBD37FtHk"
   },
   "source": [
    "## Exercise j) Forward pass unit test\n",
    "\n",
    "Write a bit of code to make a unit test that the forward pass works. This can be done by defining a simple network with for example all weights equal to one (using the ConstantInitializer method) and identity activation functions. \n",
    "\n",
    "Hints: Use the [assert](https://www.w3schools.com/python/ref_keyword_assert.asp), the nparray_to_Var and the Var_to_nparray commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "k0miqRUAFtHl"
   },
   "outputs": [],
   "source": [
    "NN = [ DenseLayer(1, 1, lambda x: x.identity(), initializer = ConstantInitializer(1.0)),\n",
    "       DenseLayer(1, 1, lambda x: x.identity(), initializer = ConstantInitializer(1.0))\n",
    "       ]\n",
    "\n",
    "inpNumpy = np.array([[1]])\n",
    "inp = nparray_to_Var(inpNumpy)\n",
    "out = forward(inp, NN)\n",
    "assert Var_to_nparray(out) == inpNumpy * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faCxhfFnFtHp"
   },
   "source": [
    "# Loss functions\n",
    "\n",
    "We are only missing a loss function to we need to define a loss function and its derivative with respect to the output of the neural network $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "I2eDYKvAFtHq"
   },
   "outputs": [],
   "source": [
    "def squared_loss(t, y):\n",
    "  \n",
    "  assert len(t) == len(y)\n",
    "  \n",
    "  def squared_loss_single(t, y):\n",
    "    Loss = Var(0.0)\n",
    "    for i in range(len(t)): # sum over outputs\n",
    "      Loss += (t[i]-y[i]) ** 2\n",
    "    return Loss\n",
    "\n",
    "  Loss = Var(0.0)\n",
    "  for n in range(len(t)): # sum over training data\n",
    "    Loss += squared_loss_single(t[n],y[n])\n",
    "  return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrwSJ2UWFtHu"
   },
   "source": [
    "## Exercise k) Implement cross entropy loss\n",
    "\n",
    "Insert code below to implement cross-entropy loss for general dimensionality of $t$. Use a logits formulation:\n",
    "$$\n",
    "\\rm{Loss} = - \\sum_i t_i \\, log \\, p_i \n",
    "$$\n",
    "with $p$ given by the the softmax function in terms of the logits $h$:\n",
    "$$\n",
    "p_i = \\frac{\\exp(h_i)}{\\sum_{i'} \\exp(h_{i'})} .\n",
    "$$\n",
    "Inserting $p$ in the expression for the loss gives\n",
    "$$\n",
    "\\rm{Loss} = - \\sum_i t_i h_i + \\rm{LogSumExp}(h) \\ ,\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\rm{LogSumExp}(h) = \\log \\sum_i \\exp h_i \\ .\n",
    "$$\n",
    "This is true for $t$ being a one-hot vector. \n",
    "\n",
    "Call the function to convince yourself it works. \n",
    "\n",
    "In practice you want to implement a [numerically stable](https://leimao.github.io/blog/LogSumExp/) version of LogSumExp. But we will not bother about that here.\n",
    "\n",
    "Help: You can add these methods in the Var class:\n",
    "\n",
    "    def exp(self):\n",
    "        return Var(exp(self.v), lambda: [(self, exp(self.v))])\n",
    "    \n",
    "    def log(self):\n",
    "        return Var(log(self.v), lambda: [(self, self.v ** -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "6nMuxyfzFtHv"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(t, h):\n",
    "    Loss = Var(0.0)\n",
    "    SE = Var(0.0)\n",
    "\n",
    "    for i in range(len(h)):\n",
    "        SE += h[i].exp()\n",
    "        Loss -= t[i] * h[i]\n",
    "\n",
    "    Loss += SE.log()\n",
    "\n",
    "    # Insert code here\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fAF5ew4FtHy"
   },
   "source": [
    "# Backward pass\n",
    "\n",
    "Now the magic happens! We get the calculation of the gradients for free. Just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iHyfPPI9Qqwu"
   },
   "outputs": [],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 5, lambda x: x.relu()),\n",
    "    DenseLayer(5, 1, lambda x: x.identity())\n",
    "]\n",
    "\n",
    "output = forward(x_train, NN)\n",
    "\n",
    "Loss = squared_loss(y_train,output)\n",
    "Loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49biIAYKQ1oG"
   },
   "source": [
    "and the gradients will be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "_rGt1bq_Q7uk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 \n",
      " Weights: [[Var(v=0.0450, grad=-19.0695), Var(v=-0.1972, grad=2.9029), Var(v=0.0439, grad=-7.3970), Var(v=-0.0426, grad=-2.0392), Var(v=-0.0332, grad=0.4782)]] Biases: [Var(v=0.0000, grad=-3.8383), Var(v=0.0000, grad=-7.6447), Var(v=0.0000, grad=-1.4889), Var(v=0.0000, grad=5.3700), Var(v=0.0000, grad=-1.2594)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=0.1323, grad=22.8204)], [Var(v=-0.1311, grad=4.3675)], [Var(v=0.0513, grad=-6.3300)], [Var(v=0.0921, grad=0.9442)], [Var(v=-0.0216, grad=0.7352)]] Biases: [Var(v=0.0000, grad=146.5460)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None]"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7d7qK0uFtH9"
   },
   "source": [
    "# Backward pass unit test\n",
    "\n",
    "Above we used finite differences to test that Nanograd is actually doing what it is supposed to do. We can in principle try the same for the neural network. But we will trust that the test above is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgBi8GOSFtIN"
   },
   "source": [
    "# Training and validation\n",
    "\n",
    "We are ready to train some neural networks!\n",
    "\n",
    "We initialize again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "01ePmzBzRtdh"
   },
   "outputs": [],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 15, lambda x: x.relu()),\n",
    "    DenseLayer(15, 50, lambda x: x.relu()),\n",
    "    DenseLayer(50, 1, lambda x: x.identity())\n",
    "]\n",
    "\n",
    "output = forward(x_train, NN)\n",
    "\n",
    "Loss = squared_loss(y_train,output)\n",
    "Loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10iRPiQ1ISHw"
   },
   "source": [
    "and make an update:\n",
    "\n",
    "We introduce a help function parameters to have a handle in all parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "dhAI7eyeznia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network before update:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=0.0275, grad=-1.8140), Var(v=-0.1074, grad=0.2514), Var(v=0.1914, grad=-10.2512), Var(v=-0.1400, grad=0.8407), Var(v=0.1161, grad=-0.4565), Var(v=0.0054, grad=6.3523), Var(v=0.1606, grad=-8.9967), Var(v=0.0102, grad=-0.8670), Var(v=0.2373, grad=-1.6632), Var(v=0.0369, grad=5.0165), Var(v=-0.0907, grad=0.7483), Var(v=-0.0937, grad=0.3056), Var(v=-0.0021, grad=-0.5586), Var(v=0.0205, grad=5.3997), Var(v=-0.0841, grad=-1.3146)]] Biases: [Var(v=0.0000, grad=-0.1956), Var(v=0.0000, grad=-0.6621), Var(v=0.0000, grad=-4.5216), Var(v=0.0000, grad=-2.2173), Var(v=0.0000, grad=-0.1087), Var(v=0.0000, grad=2.1856), Var(v=0.0000, grad=-1.9759), Var(v=0.0000, grad=0.4793), Var(v=0.0000, grad=-0.1832), Var(v=0.0000, grad=2.2515), Var(v=0.0000, grad=-1.9743), Var(v=0.0000, grad=-0.8056), Var(v=0.0000, grad=1.4613), Var(v=0.0000, grad=3.2484), Var(v=0.0000, grad=3.4566)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=0.0166, grad=1.7936), Var(v=0.0659, grad=1.5266), Var(v=-0.1077, grad=0.0000), Var(v=-0.2264, grad=0.0000), Var(v=-0.0346, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=-0.0388, grad=-1.2341), Var(v=0.1097, grad=-0.3971), Var(v=0.0612, grad=-3.9107), Var(v=0.0263, grad=1.3511), Var(v=0.0268, grad=1.4126), Var(v=-0.0974, grad=0.0000), Var(v=-0.0132, grad=0.0000), Var(v=-0.0712, grad=0.0000), Var(v=-0.0534, grad=0.0000), Var(v=-0.0715, grad=-14.0822), Var(v=0.0689, grad=0.2178), Var(v=-0.0551, grad=0.0000), Var(v=0.0370, grad=-12.8020), Var(v=-0.0157, grad=0.1425), Var(v=-0.1395, grad=0.0000), Var(v=-0.0569, grad=0.0000), Var(v=0.1527, grad=-0.3987), Var(v=-0.0133, grad=0.0000), Var(v=-0.0251, grad=-2.2438), Var(v=-0.1238, grad=0.0000), Var(v=-0.0152, grad=14.1133), Var(v=-0.1657, grad=0.0000), Var(v=0.0545, grad=-13.9537), Var(v=-0.0843, grad=0.0000), Var(v=0.1167, grad=0.3116), Var(v=-0.1430, grad=0.0000), Var(v=-0.0321, grad=0.1156), Var(v=0.0499, grad=0.3514), Var(v=-0.0009, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.1121, grad=1.0931), Var(v=-0.1340, grad=0.0000), Var(v=-0.0171, grad=-5.2349), Var(v=0.1471, grad=2.0033), Var(v=-0.1506, grad=0.0000), Var(v=0.1253, grad=-1.3357), Var(v=0.1717, grad=3.0590), Var(v=-0.0756, grad=0.0000), Var(v=0.0151, grad=-1.4543), Var(v=-0.0286, grad=0.0000), Var(v=-0.0717, grad=0.0000), Var(v=-0.0855, grad=0.0000), Var(v=0.1658, grad=-0.7410), Var(v=-0.1126, grad=-5.2200)], [Var(v=0.0585, grad=0.1927), Var(v=-0.2044, grad=0.1640), Var(v=-0.0154, grad=0.0000), Var(v=-0.0458, grad=0.0000), Var(v=-0.0820, grad=0.0000), Var(v=-0.1614, grad=0.0000), Var(v=0.0329, grad=0.0000), Var(v=-0.0703, grad=-0.0427), Var(v=0.0677, grad=-0.0926), Var(v=-0.0332, grad=0.1451), Var(v=-0.0473, grad=0.1517), Var(v=0.0233, grad=0.0000), Var(v=-0.0895, grad=0.0000), Var(v=-0.0166, grad=0.0000), Var(v=-0.1834, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=-0.1157, grad=0.0234), Var(v=-0.0607, grad=0.0000), Var(v=-0.0252, grad=-0.3132), Var(v=0.0173, grad=0.0085), Var(v=0.0504, grad=0.0000), Var(v=0.0674, grad=0.0000), Var(v=-0.1245, grad=-0.0428), Var(v=0.1373, grad=0.0000), Var(v=-0.0483, grad=0.0000), Var(v=0.0671, grad=0.0000), Var(v=-0.0646, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=0.0481, grad=-0.4009), Var(v=0.1182, grad=0.0000), Var(v=0.0748, grad=0.0335), Var(v=0.0199, grad=0.0000), Var(v=0.0170, grad=0.0000), Var(v=-0.0243, grad=0.0377), Var(v=-0.0693, grad=0.0000), Var(v=-0.1484, grad=0.0000), Var(v=0.0285, grad=0.1174), Var(v=0.0517, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0151, grad=0.2152), Var(v=0.0114, grad=0.0000), Var(v=-0.0691, grad=-0.1435), Var(v=0.0482, grad=0.3286), Var(v=-0.0078, grad=0.0000), Var(v=-0.0137, grad=-0.1562), Var(v=-0.1593, grad=0.0000), Var(v=0.1734, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=0.1315, grad=-0.0796), Var(v=0.0147, grad=0.0000)], [Var(v=0.0798, grad=-2.2917), Var(v=0.1039, grad=-1.9505), Var(v=0.0357, grad=0.0000), Var(v=-0.0478, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=0.0197, grad=0.0000), Var(v=0.0233, grad=-0.5443), Var(v=-0.0099, grad=0.5074), Var(v=-0.0329, grad=-0.1128), Var(v=-0.0473, grad=-1.7262), Var(v=-0.0478, grad=-1.8049), Var(v=-0.1104, grad=0.0000), Var(v=-0.2209, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=0.0101, grad=0.0000), Var(v=0.1217, grad=-5.6177), Var(v=0.0416, grad=-0.2783), Var(v=-0.0494, grad=0.0000), Var(v=-0.1263, grad=-0.2820), Var(v=-0.0576, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.0742, grad=0.0000), Var(v=0.0831, grad=0.5095), Var(v=-0.0189, grad=0.0000), Var(v=0.1876, grad=-1.1076), Var(v=0.0356, grad=0.0000), Var(v=-0.1110, grad=5.8746), Var(v=0.0346, grad=0.0000), Var(v=0.1570, grad=0.3203), Var(v=0.1920, grad=0.0000), Var(v=0.0342, grad=-0.3981), Var(v=-0.0448, grad=0.0000), Var(v=-0.1048, grad=0.0575), Var(v=-0.0749, grad=-0.4490), Var(v=0.0532, grad=0.0000), Var(v=-0.1832, grad=0.0000), Var(v=-0.0057, grad=-1.3966), Var(v=0.1255, grad=0.0000), Var(v=0.0799, grad=-2.3004), Var(v=0.0318, grad=-2.5595), Var(v=0.0560, grad=0.0000), Var(v=0.0304, grad=1.7066), Var(v=-0.1008, grad=-3.9084), Var(v=-0.0914, grad=0.0000), Var(v=-0.0807, grad=1.8581), Var(v=0.0240, grad=0.0000), Var(v=-0.0146, grad=0.0000), Var(v=-0.2539, grad=0.0000), Var(v=-0.0070, grad=0.9468), Var(v=0.1439, grad=-2.4299)], [Var(v=-0.2066, grad=0.2511), Var(v=-0.1144, grad=0.2137), Var(v=-0.0585, grad=0.0000), Var(v=-0.0484, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=-0.1901, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=0.0427, grad=-0.0556), Var(v=-0.0241, grad=-0.1207), Var(v=0.0115, grad=0.1891), Var(v=0.1227, grad=0.1977), Var(v=-0.2380, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=-0.0489, grad=0.0000), Var(v=0.0338, grad=0.0000), Var(v=0.0988, grad=0.0000), Var(v=0.0039, grad=0.0305), Var(v=-0.0117, grad=0.0000), Var(v=-0.0306, grad=-0.4081), Var(v=0.1041, grad=0.0111), Var(v=-0.0933, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.1230, grad=-0.0558), Var(v=0.0409, grad=0.0000), Var(v=-0.1081, grad=0.0000), Var(v=-0.0182, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=0.0281, grad=0.0000), Var(v=0.1517, grad=-0.5223), Var(v=0.0495, grad=0.0000), Var(v=0.0275, grad=0.0436), Var(v=-0.1799, grad=0.0000), Var(v=-0.0385, grad=0.0000), Var(v=0.0281, grad=0.0492), Var(v=0.0418, grad=0.0000), Var(v=-0.1429, grad=0.0000), Var(v=0.0966, grad=0.1530), Var(v=-0.0150, grad=0.0000), Var(v=-0.1462, grad=0.0000), Var(v=0.0020, grad=0.2804), Var(v=0.0413, grad=0.0000), Var(v=-0.0814, grad=-0.1870), Var(v=-0.1154, grad=0.4282), Var(v=0.0563, grad=0.0000), Var(v=0.0040, grad=-0.2036), Var(v=-0.1062, grad=0.0000), Var(v=-0.0002, grad=0.0000), Var(v=-0.0668, grad=0.0000), Var(v=-0.0705, grad=-0.1037), Var(v=-0.0911, grad=0.0000)], [Var(v=0.0336, grad=-1.3905), Var(v=-0.0205, grad=-1.1835), Var(v=-0.1034, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0964, grad=0.0000), Var(v=-0.0007, grad=0.0000), Var(v=-0.0113, grad=-0.3303), Var(v=-0.0745, grad=0.3078), Var(v=0.1230, grad=-0.0684), Var(v=-0.0304, grad=-1.0474), Var(v=0.2446, grad=-1.0951), Var(v=-0.0176, grad=0.0000), Var(v=0.1284, grad=0.0000), Var(v=0.0594, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0604, grad=-3.4085), Var(v=-0.0499, grad=-0.1688), Var(v=0.0720, grad=0.0000), Var(v=-0.0399, grad=-0.1711), Var(v=-0.0921, grad=0.0000), Var(v=0.1080, grad=0.0000), Var(v=-0.0284, grad=0.0000), Var(v=-0.0630, grad=0.3091), Var(v=0.0603, grad=0.0000), Var(v=-0.0999, grad=-0.6720), Var(v=-0.1504, grad=0.0000), Var(v=-0.0035, grad=3.5644), Var(v=-0.0635, grad=0.0000), Var(v=-0.1660, grad=0.1944), Var(v=-0.0632, grad=0.0000), Var(v=0.1195, grad=-0.2416), Var(v=-0.0906, grad=0.0000), Var(v=0.1232, grad=0.0349), Var(v=0.0045, grad=-0.2724), Var(v=-0.0173, grad=0.0000), Var(v=0.0075, grad=0.0000), Var(v=0.1275, grad=-0.8474), Var(v=0.1090, grad=0.0000), Var(v=0.1892, grad=-1.3958), Var(v=-0.1607, grad=-1.5530), Var(v=-0.1448, grad=0.0000), Var(v=0.0345, grad=1.0355), Var(v=-0.1105, grad=-2.3714), Var(v=-0.0291, grad=0.0000), Var(v=0.2465, grad=1.1274), Var(v=0.0332, grad=0.0000), Var(v=-0.1336, grad=0.0000), Var(v=-0.2128, grad=0.0000), Var(v=-0.0249, grad=0.5745), Var(v=-0.0053, grad=-1.4743)], [Var(v=-0.0178, grad=-0.0648), Var(v=0.0400, grad=-0.0552), Var(v=0.0714, grad=0.0000), Var(v=-0.0860, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0188, grad=-0.0154), Var(v=0.1782, grad=0.0144), Var(v=-0.0180, grad=-0.0032), Var(v=-0.0146, grad=-0.0488), Var(v=0.0477, grad=-0.0511), Var(v=-0.1092, grad=0.0000), Var(v=-0.0613, grad=0.0000), Var(v=0.1298, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0185, grad=-0.1589), Var(v=0.0195, grad=-0.0079), Var(v=0.2199, grad=0.0000), Var(v=-0.0291, grad=-0.0080), Var(v=-0.0963, grad=0.0000), Var(v=-0.0333, grad=0.0000), Var(v=-0.0972, grad=0.0000), Var(v=-0.0322, grad=0.0144), Var(v=-0.1003, grad=0.0000), Var(v=-0.1782, grad=-0.0313), Var(v=-0.0075, grad=0.0000), Var(v=0.0490, grad=0.1662), Var(v=-0.1185, grad=0.0000), Var(v=0.0462, grad=0.0091), Var(v=-0.1076, grad=0.0000), Var(v=-0.1257, grad=-0.0113), Var(v=0.1579, grad=0.0000), Var(v=0.0871, grad=0.0016), Var(v=0.0538, grad=-0.0127), Var(v=0.0073, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.1623, grad=-0.0395), Var(v=0.1191, grad=0.0000), Var(v=0.0430, grad=-0.0651), Var(v=0.0136, grad=-0.0724), Var(v=-0.0304, grad=0.0000), Var(v=0.0448, grad=0.0483), Var(v=-0.0720, grad=-0.1106), Var(v=-0.2023, grad=0.0000), Var(v=0.1345, grad=0.0526), Var(v=-0.1599, grad=0.0000), Var(v=-0.0197, grad=0.0000), Var(v=0.0097, grad=0.0000), Var(v=-0.0506, grad=0.0268), Var(v=-0.1691, grad=-0.0687)], [Var(v=0.2087, grad=-1.9233), Var(v=0.0915, grad=-1.6370), Var(v=0.0857, grad=0.0000), Var(v=-0.2246, grad=0.0000), Var(v=-0.0547, grad=0.0000), Var(v=0.0900, grad=0.0000), Var(v=0.0245, grad=-0.4568), Var(v=0.0318, grad=0.4258), Var(v=-0.0180, grad=-0.0947), Var(v=0.0223, grad=-1.4487), Var(v=0.0760, grad=-1.5147), Var(v=0.0375, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=0.0610, grad=0.0000), Var(v=0.0564, grad=-4.7147), Var(v=0.1308, grad=-0.2335), Var(v=-0.0058, grad=0.0000), Var(v=0.0216, grad=-0.2367), Var(v=-0.0431, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.1059, grad=0.0000), Var(v=-0.0016, grad=0.4276), Var(v=0.0723, grad=0.0000), Var(v=0.2760, grad=-0.9296), Var(v=0.1042, grad=0.0000), Var(v=0.0135, grad=4.9302), Var(v=0.0148, grad=0.0000), Var(v=-0.1436, grad=0.2688), Var(v=-0.0703, grad=0.0000), Var(v=-0.0232, grad=-0.3341), Var(v=-0.0006, grad=0.0000), Var(v=-0.0096, grad=0.0482), Var(v=0.1422, grad=-0.3768), Var(v=-0.1899, grad=0.0000), Var(v=0.0425, grad=0.0000), Var(v=-0.0086, grad=-1.1721), Var(v=-0.0573, grad=0.0000), Var(v=-0.0327, grad=-1.9306), Var(v=0.0317, grad=-2.1481), Var(v=0.0035, grad=0.0000), Var(v=0.0680, grad=1.4323), Var(v=0.0535, grad=-3.2801), Var(v=0.2524, grad=0.0000), Var(v=0.0142, grad=1.5594), Var(v=-0.0919, grad=0.0000), Var(v=-0.1040, grad=0.0000), Var(v=0.0793, grad=0.0000), Var(v=0.0111, grad=0.7946), Var(v=0.0644, grad=-2.0393)], [Var(v=0.0903, grad=-0.1219), Var(v=0.0022, grad=-0.1038), Var(v=-0.0046, grad=0.0000), Var(v=0.0057, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0251, grad=0.0000), Var(v=-0.0288, grad=-0.0290), Var(v=-0.0022, grad=0.0270), Var(v=-0.0941, grad=-0.0060), Var(v=-0.1253, grad=-0.0918), Var(v=-0.0884, grad=-0.0960), Var(v=-0.0206, grad=0.0000), Var(v=-0.1337, grad=0.0000), Var(v=-0.2874, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=-0.0607, grad=-0.2988), Var(v=0.0204, grad=-0.0148), Var(v=-0.0617, grad=0.0000), Var(v=0.0531, grad=-0.0150), Var(v=-0.0680, grad=0.0000), Var(v=0.0307, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=0.0919, grad=0.0271), Var(v=-0.0880, grad=0.0000), Var(v=0.0401, grad=-0.0589), Var(v=0.1206, grad=0.0000), Var(v=-0.0247, grad=0.3125), Var(v=0.0725, grad=0.0000), Var(v=-0.1656, grad=0.0170), Var(v=0.0238, grad=0.0000), Var(v=0.0829, grad=-0.0212), Var(v=0.1146, grad=0.0000), Var(v=-0.1115, grad=0.0031), Var(v=0.1687, grad=-0.0239), Var(v=0.0013, grad=0.0000), Var(v=-0.1077, grad=0.0000), Var(v=0.0063, grad=-0.0743), Var(v=0.0285, grad=0.0000), Var(v=0.1170, grad=-0.1224), Var(v=-0.1176, grad=-0.1362), Var(v=0.1038, grad=0.0000), Var(v=-0.1069, grad=0.0908), Var(v=0.0417, grad=-0.2079), Var(v=-0.0762, grad=0.0000), Var(v=-0.0628, grad=0.0988), Var(v=0.0378, grad=0.0000), Var(v=-0.1536, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0037, grad=0.0504), Var(v=-0.0289, grad=-0.1293)], [Var(v=-0.0046, grad=-2.8418), Var(v=0.0583, grad=-2.4188), Var(v=0.0809, grad=0.0000), Var(v=0.1248, grad=0.0000), Var(v=0.2008, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0834, grad=-0.6750), Var(v=-0.0444, grad=0.6292), Var(v=-0.2326, grad=-0.1399), Var(v=0.0999, grad=-2.1406), Var(v=0.1619, grad=-2.2381), Var(v=-0.0403, grad=0.0000), Var(v=0.0246, grad=0.0000), Var(v=-0.0078, grad=0.0000), Var(v=0.0591, grad=0.0000), Var(v=0.2026, grad=-6.9663), Var(v=-0.1851, grad=-0.3451), Var(v=-0.0578, grad=0.0000), Var(v=-0.0092, grad=-0.3497), Var(v=-0.0050, grad=0.0000), Var(v=-0.0611, grad=0.0000), Var(v=-0.0501, grad=0.0000), Var(v=-0.0418, grad=0.6318), Var(v=-0.0807, grad=0.0000), Var(v=0.1046, grad=-1.3735), Var(v=-0.1437, grad=0.0000), Var(v=0.1544, grad=7.2848), Var(v=0.0748, grad=0.0000), Var(v=-0.0456, grad=0.3972), Var(v=0.0482, grad=0.0000), Var(v=0.0507, grad=-0.4937), Var(v=-0.0799, grad=0.0000), Var(v=0.1132, grad=0.0713), Var(v=-0.0830, grad=-0.5568), Var(v=-0.0547, grad=0.0000), Var(v=0.0353, grad=0.0000), Var(v=-0.0120, grad=-1.7319), Var(v=-0.1886, grad=0.0000), Var(v=-0.0439, grad=-2.8526), Var(v=0.0194, grad=-3.1740), Var(v=-0.1426, grad=0.0000), Var(v=0.0224, grad=2.1163), Var(v=-0.1089, grad=-4.8466), Var(v=-0.0764, grad=0.0000), Var(v=0.1054, grad=2.3041), Var(v=-0.0156, grad=0.0000), Var(v=-0.0812, grad=0.0000), Var(v=-0.0710, grad=0.0000), Var(v=-0.1166, grad=1.1741), Var(v=0.0088, grad=-3.0132)], [Var(v=-0.1647, grad=-0.4424), Var(v=-0.0729, grad=-0.3765), Var(v=-0.0080, grad=0.0000), Var(v=-0.0279, grad=0.0000), Var(v=-0.1489, grad=0.0000), Var(v=0.0016, grad=0.0000), Var(v=-0.0323, grad=-0.1051), Var(v=-0.1110, grad=0.0979), Var(v=-0.1003, grad=-0.0218), Var(v=-0.0278, grad=-0.3332), Var(v=-0.1152, grad=-0.3484), Var(v=0.0670, grad=0.0000), Var(v=-0.1300, grad=0.0000), Var(v=0.0996, grad=0.0000), Var(v=-0.0229, grad=0.0000), Var(v=-0.0673, grad=-1.0844), Var(v=0.1025, grad=-0.0537), Var(v=-0.0106, grad=0.0000), Var(v=0.0671, grad=-0.0544), Var(v=-0.0324, grad=0.0000), Var(v=0.0089, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.0678, grad=0.0983), Var(v=-0.0381, grad=0.0000), Var(v=-0.2120, grad=-0.2138), Var(v=0.0322, grad=0.0000), Var(v=0.1040, grad=1.1340), Var(v=0.0877, grad=0.0000), Var(v=-0.2132, grad=0.0618), Var(v=0.0221, grad=0.0000), Var(v=-0.0092, grad=-0.0768), Var(v=-0.0747, grad=0.0000), Var(v=-0.0868, grad=0.0111), Var(v=-0.0067, grad=-0.0867), Var(v=0.1365, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0699, grad=-0.2696), Var(v=-0.0749, grad=0.0000), Var(v=0.0995, grad=-0.4440), Var(v=-0.1489, grad=-0.4941), Var(v=0.0921, grad=0.0000), Var(v=-0.1382, grad=0.3294), Var(v=-0.0379, grad=-0.7544), Var(v=0.0450, grad=0.0000), Var(v=-0.0832, grad=0.3587), Var(v=0.1065, grad=0.0000), Var(v=-0.0156, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=0.1213, grad=0.1828), Var(v=0.3536, grad=-0.4691)], [Var(v=-0.0340, grad=0.1627), Var(v=-0.1450, grad=0.1385), Var(v=-0.0673, grad=0.0000), Var(v=0.1058, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0470, grad=0.0000), Var(v=0.0572, grad=-0.0360), Var(v=0.1227, grad=-0.0782), Var(v=-0.1058, grad=0.1226), Var(v=-0.1555, grad=0.1281), Var(v=0.0152, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1168, grad=0.0000), Var(v=0.0565, grad=0.0000), Var(v=-0.0386, grad=0.0000), Var(v=0.0799, grad=0.0198), Var(v=-0.0232, grad=0.0000), Var(v=0.2325, grad=-0.2645), Var(v=0.1019, grad=0.0072), Var(v=0.0803, grad=0.0000), Var(v=0.0559, grad=0.0000), Var(v=0.0311, grad=-0.0362), Var(v=-0.0357, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.1548, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.0639, grad=0.0000), Var(v=-0.1356, grad=-0.3385), Var(v=-0.1196, grad=0.0000), Var(v=0.0577, grad=0.0283), Var(v=0.2020, grad=0.0000), Var(v=0.2109, grad=0.0000), Var(v=0.1286, grad=0.0319), Var(v=-0.1079, grad=0.0000), Var(v=0.0933, grad=0.0000), Var(v=0.0771, grad=0.0992), Var(v=0.1385, grad=0.0000), Var(v=0.0876, grad=0.0000), Var(v=0.1231, grad=0.1817), Var(v=0.1716, grad=0.0000), Var(v=0.1361, grad=-0.1212), Var(v=-0.0870, grad=0.2775), Var(v=-0.3042, grad=0.0000), Var(v=-0.0927, grad=-0.1319), Var(v=0.0441, grad=0.0000), Var(v=-0.1991, grad=0.0000), Var(v=0.0273, grad=0.0000), Var(v=-0.1392, grad=-0.0672), Var(v=-0.0137, grad=0.0000)], [Var(v=-0.0988, grad=0.1680), Var(v=0.0196, grad=0.1430), Var(v=-0.0127, grad=0.0000), Var(v=0.1999, grad=0.0000), Var(v=-0.0897, grad=0.0000), Var(v=-0.0076, grad=0.0000), Var(v=0.0267, grad=0.0000), Var(v=0.1173, grad=-0.0372), Var(v=-0.0517, grad=-0.0808), Var(v=0.0316, grad=0.1266), Var(v=0.0696, grad=0.1323), Var(v=-0.1520, grad=0.0000), Var(v=0.0177, grad=0.0000), Var(v=0.1819, grad=0.0000), Var(v=0.0069, grad=0.0000), Var(v=0.0539, grad=0.0000), Var(v=-0.0463, grad=0.0204), Var(v=0.0837, grad=0.0000), Var(v=-0.1294, grad=-0.2731), Var(v=0.0326, grad=0.0074), Var(v=0.0456, grad=0.0000), Var(v=0.1214, grad=0.0000), Var(v=0.0429, grad=-0.0374), Var(v=-0.0056, grad=0.0000), Var(v=-0.0281, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0781, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=0.0842, grad=-0.3496), Var(v=-0.1031, grad=0.0000), Var(v=-0.1383, grad=0.0292), Var(v=0.0627, grad=0.0000), Var(v=0.0982, grad=0.0000), Var(v=0.1570, grad=0.0329), Var(v=0.0466, grad=0.0000), Var(v=-0.0339, grad=0.0000), Var(v=-0.0242, grad=0.1024), Var(v=-0.0968, grad=0.0000), Var(v=0.0136, grad=0.0000), Var(v=-0.0292, grad=0.1877), Var(v=0.0200, grad=0.0000), Var(v=0.0463, grad=-0.1251), Var(v=-0.0789, grad=0.2866), Var(v=0.0750, grad=0.0000), Var(v=-0.0240, grad=-0.1362), Var(v=0.0121, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0074, grad=-0.0694), Var(v=-0.0006, grad=0.0000)], [Var(v=-0.0581, grad=0.0038), Var(v=0.1351, grad=0.0032), Var(v=0.0019, grad=0.0000), Var(v=0.1467, grad=0.0000), Var(v=-0.1703, grad=0.0000), Var(v=0.0694, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.0754, grad=-0.0008), Var(v=0.1026, grad=-0.0018), Var(v=-0.0836, grad=0.0029), Var(v=0.0724, grad=0.0030), Var(v=-0.1760, grad=0.0000), Var(v=0.1511, grad=0.0000), Var(v=-0.0570, grad=0.0000), Var(v=0.0858, grad=0.0000), Var(v=0.1266, grad=0.0000), Var(v=0.0130, grad=0.0005), Var(v=-0.1708, grad=0.0000), Var(v=0.0070, grad=-0.0062), Var(v=0.1116, grad=0.0002), Var(v=-0.0269, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.1170, grad=-0.0008), Var(v=-0.0785, grad=0.0000), Var(v=0.0451, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0238, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=-0.0728, grad=-0.0079), Var(v=-0.0361, grad=0.0000), Var(v=0.0046, grad=0.0007), Var(v=-0.0185, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0237, grad=0.0007), Var(v=-0.1411, grad=0.0000), Var(v=-0.1114, grad=0.0000), Var(v=-0.0273, grad=0.0023), Var(v=0.1794, grad=0.0000), Var(v=0.1429, grad=0.0000), Var(v=0.2494, grad=0.0042), Var(v=0.0980, grad=0.0000), Var(v=-0.1321, grad=-0.0028), Var(v=-0.1715, grad=0.0065), Var(v=-0.0970, grad=0.0000), Var(v=-0.1031, grad=-0.0031), Var(v=-0.0453, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=0.0500, grad=0.0000), Var(v=0.0073, grad=-0.0016), Var(v=-0.1355, grad=0.0000)], [Var(v=0.0352, grad=-0.2456), Var(v=0.1224, grad=-0.2091), Var(v=0.0014, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=-0.1973, grad=0.0000), Var(v=-0.0286, grad=0.0000), Var(v=-0.1854, grad=-0.0583), Var(v=0.0295, grad=0.0544), Var(v=-0.1809, grad=-0.0121), Var(v=0.0365, grad=-0.1850), Var(v=-0.1724, grad=-0.1935), Var(v=-0.1822, grad=0.0000), Var(v=0.1642, grad=0.0000), Var(v=0.0739, grad=0.0000), Var(v=-0.1425, grad=0.0000), Var(v=-0.1742, grad=-0.6021), Var(v=-0.0974, grad=-0.0298), Var(v=0.0604, grad=0.0000), Var(v=-0.1540, grad=-0.0302), Var(v=-0.0924, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=0.0153, grad=0.0000), Var(v=0.0871, grad=0.0546), Var(v=-0.1542, grad=0.0000), Var(v=0.1162, grad=-0.1187), Var(v=-0.0372, grad=0.0000), Var(v=-0.0002, grad=0.6297), Var(v=0.0034, grad=0.0000), Var(v=-0.0833, grad=0.0343), Var(v=-0.0334, grad=0.0000), Var(v=-0.0166, grad=-0.0427), Var(v=0.2207, grad=0.0000), Var(v=-0.1543, grad=0.0062), Var(v=-0.0049, grad=-0.0481), Var(v=0.0104, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0435, grad=-0.1497), Var(v=0.2960, grad=0.0000), Var(v=0.0631, grad=-0.2466), Var(v=-0.0811, grad=-0.2744), Var(v=-0.1599, grad=0.0000), Var(v=0.0068, grad=0.1829), Var(v=-0.0637, grad=-0.4189), Var(v=0.0693, grad=0.0000), Var(v=0.1322, grad=0.1992), Var(v=0.1107, grad=0.0000), Var(v=0.0028, grad=0.0000), Var(v=0.0761, grad=0.0000), Var(v=-0.0642, grad=0.1015), Var(v=0.1711, grad=-0.2605)], [Var(v=0.0886, grad=0.1509), Var(v=0.1452, grad=0.1284), Var(v=0.1109, grad=0.0000), Var(v=-0.0454, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0280, grad=0.0000), Var(v=0.1577, grad=0.0000), Var(v=0.0212, grad=-0.0334), Var(v=0.1314, grad=-0.0725), Var(v=-0.0586, grad=0.1137), Var(v=0.1197, grad=0.1188), Var(v=0.1125, grad=0.0000), Var(v=-0.0833, grad=0.0000), Var(v=0.1944, grad=0.0000), Var(v=0.1960, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=-0.0383, grad=0.0183), Var(v=-0.0211, grad=0.0000), Var(v=-0.1824, grad=-0.2453), Var(v=0.0013, grad=0.0067), Var(v=-0.0931, grad=0.0000), Var(v=-0.0235, grad=0.0000), Var(v=0.0094, grad=-0.0335), Var(v=-0.1651, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0500, grad=0.0000), Var(v=0.0639, grad=-0.3140), Var(v=-0.0227, grad=0.0000), Var(v=0.0820, grad=0.0262), Var(v=-0.0644, grad=0.0000), Var(v=0.0834, grad=0.0000), Var(v=0.0580, grad=0.0296), Var(v=-0.1040, grad=0.0000), Var(v=-0.0875, grad=0.0000), Var(v=0.0901, grad=0.0920), Var(v=-0.0046, grad=0.0000), Var(v=-0.1068, grad=0.0000), Var(v=-0.0450, grad=0.1685), Var(v=0.1555, grad=0.0000), Var(v=-0.0848, grad=-0.1124), Var(v=0.0841, grad=0.2574), Var(v=0.1532, grad=0.0000), Var(v=-0.1298, grad=-0.1224), Var(v=0.0984, grad=0.0000), Var(v=0.0787, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0958, grad=-0.0623), Var(v=-0.0116, grad=0.0000)]] Biases: [Var(v=0.0000, grad=31.8404), Var(v=0.0000, grad=27.1002), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-17.3399), Var(v=0.0000, grad=-7.0493), Var(v=0.0000, grad=-58.4178), Var(v=0.0000, grad=23.9839), Var(v=0.0000, grad=25.0765), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-199.1327), Var(v=0.0000, grad=3.8662), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-191.4219), Var(v=0.0000, grad=2.1381), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-7.0785), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-31.2711), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=199.0471), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-209.9952), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=5.5313), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=1.6108), Var(v=0.0000, grad=6.2379), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=19.4048), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-73.5689), Var(v=0.0000, grad=35.5619), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-23.7113), Var(v=0.0000, grad=54.3025), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-25.8159), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-13.1544), Var(v=0.0000, grad=-73.0668)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=0.0822, grad=18.7372)], [Var(v=0.0699, grad=-6.0868)], [Var(v=0.0642, grad=0.0000)], [Var(v=-0.1283, grad=0.0000)], [Var(v=-0.2168, grad=0.0000)], [Var(v=0.3005, grad=0.0000)], [Var(v=0.0217, grad=-0.6340)], [Var(v=-0.0182, grad=5.4561)], [Var(v=-0.0395, grad=5.6571)], [Var(v=0.0619, grad=-1.6308)], [Var(v=0.0647, grad=-8.0501)], [Var(v=0.1217, grad=0.0000)], [Var(v=-0.0547, grad=0.0000)], [Var(v=-0.1258, grad=0.0000)], [Var(v=-0.0202, grad=0.0000)], [Var(v=0.1829, grad=-7.4380)], [Var(v=0.0100, grad=3.9578)], [Var(v=0.2897, grad=0.0000)], [Var(v=-0.1335, grad=2.9441)], [Var(v=0.0149, grad=0.0051)], [Var(v=0.0060, grad=0.0000)], [Var(v=0.1579, grad=0.0000)], [Var(v=-0.0183, grad=2.3254)], [Var(v=0.1643, grad=0.0000)], [Var(v=0.0388, grad=-11.5818)], [Var(v=-0.0425, grad=0.0000)], [Var(v=-0.1959, grad=-2.2019)], [Var(v=0.1258, grad=0.0000)], [Var(v=-0.1709, grad=5.3765)], [Var(v=-0.1015, grad=0.0000)], [Var(v=0.0143, grad=-1.3214)], [Var(v=0.1176, grad=0.0000)], [Var(v=-0.0141, grad=-0.0039)], [Var(v=0.0161, grad=3.1152)], [Var(v=-0.1154, grad=0.0000)], [Var(v=0.0503, grad=0.0000)], [Var(v=0.0501, grad=1.0521)], [Var(v=-0.0232, grad=0.0000)], [Var(v=0.0785, grad=-3.1417)], [Var(v=0.0918, grad=4.9239)], [Var(v=-0.0399, grad=0.0000)], [Var(v=-0.0612, grad=-0.4231)], [Var(v=0.1401, grad=10.9108)], [Var(v=0.1351, grad=0.0000)], [Var(v=-0.0666, grad=-6.0248)], [Var(v=-0.1731, grad=0.0000)], [Var(v=0.1245, grad=0.0000)], [Var(v=0.0025, grad=0.0000)], [Var(v=-0.0339, grad=7.2136)], [Var(v=0.1241, grad=-0.8595)]] Biases: [Var(v=0.0000, grad=1291.9406)]\n",
      "\n",
      "Network after update:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=0.0456, grad=-1.8140), Var(v=-0.1100, grad=0.2514), Var(v=0.2939, grad=-10.2512), Var(v=-0.1484, grad=0.8407), Var(v=0.1207, grad=-0.4565), Var(v=-0.0581, grad=6.3523), Var(v=0.2506, grad=-8.9967), Var(v=0.0189, grad=-0.8670), Var(v=0.2540, grad=-1.6632), Var(v=-0.0132, grad=5.0165), Var(v=-0.0982, grad=0.7483), Var(v=-0.0968, grad=0.3056), Var(v=0.0035, grad=-0.5586), Var(v=-0.0335, grad=5.3997), Var(v=-0.0710, grad=-1.3146)]] Biases: [Var(v=0.0020, grad=-0.1956), Var(v=0.0066, grad=-0.6621), Var(v=0.0452, grad=-4.5216), Var(v=0.0222, grad=-2.2173), Var(v=0.0011, grad=-0.1087), Var(v=-0.0219, grad=2.1856), Var(v=0.0198, grad=-1.9759), Var(v=-0.0048, grad=0.4793), Var(v=0.0018, grad=-0.1832), Var(v=-0.0225, grad=2.2515), Var(v=0.0197, grad=-1.9743), Var(v=0.0081, grad=-0.8056), Var(v=-0.0146, grad=1.4613), Var(v=-0.0325, grad=3.2484), Var(v=-0.0346, grad=3.4566)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=-0.0013, grad=1.7936), Var(v=0.0507, grad=1.5266), Var(v=-0.1077, grad=0.0000), Var(v=-0.2264, grad=0.0000), Var(v=-0.0346, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=-0.0264, grad=-1.2341), Var(v=0.1137, grad=-0.3971), Var(v=0.1003, grad=-3.9107), Var(v=0.0128, grad=1.3511), Var(v=0.0127, grad=1.4126), Var(v=-0.0974, grad=0.0000), Var(v=-0.0132, grad=0.0000), Var(v=-0.0712, grad=0.0000), Var(v=-0.0534, grad=0.0000), Var(v=0.0693, grad=-14.0822), Var(v=0.0667, grad=0.2178), Var(v=-0.0551, grad=0.0000), Var(v=0.1650, grad=-12.8020), Var(v=-0.0171, grad=0.1425), Var(v=-0.1395, grad=0.0000), Var(v=-0.0569, grad=0.0000), Var(v=0.1567, grad=-0.3987), Var(v=-0.0133, grad=0.0000), Var(v=-0.0026, grad=-2.2438), Var(v=-0.1238, grad=0.0000), Var(v=-0.1563, grad=14.1133), Var(v=-0.1657, grad=0.0000), Var(v=0.1940, grad=-13.9537), Var(v=-0.0843, grad=0.0000), Var(v=0.1136, grad=0.3116), Var(v=-0.1430, grad=0.0000), Var(v=-0.0332, grad=0.1156), Var(v=0.0464, grad=0.3514), Var(v=-0.0009, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.1012, grad=1.0931), Var(v=-0.1340, grad=0.0000), Var(v=0.0352, grad=-5.2349), Var(v=0.1271, grad=2.0033), Var(v=-0.1506, grad=0.0000), Var(v=0.1386, grad=-1.3357), Var(v=0.1411, grad=3.0590), Var(v=-0.0756, grad=0.0000), Var(v=0.0296, grad=-1.4543), Var(v=-0.0286, grad=0.0000), Var(v=-0.0717, grad=0.0000), Var(v=-0.0855, grad=0.0000), Var(v=0.1732, grad=-0.7410), Var(v=-0.0604, grad=-5.2200)], [Var(v=0.0566, grad=0.1927), Var(v=-0.2060, grad=0.1640), Var(v=-0.0154, grad=0.0000), Var(v=-0.0458, grad=0.0000), Var(v=-0.0820, grad=0.0000), Var(v=-0.1614, grad=0.0000), Var(v=0.0329, grad=0.0000), Var(v=-0.0698, grad=-0.0427), Var(v=0.0687, grad=-0.0926), Var(v=-0.0347, grad=0.1451), Var(v=-0.0488, grad=0.1517), Var(v=0.0233, grad=0.0000), Var(v=-0.0895, grad=0.0000), Var(v=-0.0166, grad=0.0000), Var(v=-0.1834, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=-0.1160, grad=0.0234), Var(v=-0.0607, grad=0.0000), Var(v=-0.0221, grad=-0.3132), Var(v=0.0172, grad=0.0085), Var(v=0.0504, grad=0.0000), Var(v=0.0674, grad=0.0000), Var(v=-0.1240, grad=-0.0428), Var(v=0.1373, grad=0.0000), Var(v=-0.0483, grad=0.0000), Var(v=0.0671, grad=0.0000), Var(v=-0.0646, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=0.0521, grad=-0.4009), Var(v=0.1182, grad=0.0000), Var(v=0.0744, grad=0.0335), Var(v=0.0199, grad=0.0000), Var(v=0.0170, grad=0.0000), Var(v=-0.0247, grad=0.0377), Var(v=-0.0693, grad=0.0000), Var(v=-0.1484, grad=0.0000), Var(v=0.0273, grad=0.1174), Var(v=0.0517, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0172, grad=0.2152), Var(v=0.0114, grad=0.0000), Var(v=-0.0677, grad=-0.1435), Var(v=0.0449, grad=0.3286), Var(v=-0.0078, grad=0.0000), Var(v=-0.0122, grad=-0.1562), Var(v=-0.1593, grad=0.0000), Var(v=0.1734, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=0.1323, grad=-0.0796), Var(v=0.0147, grad=0.0000)], [Var(v=0.1027, grad=-2.2917), Var(v=0.1235, grad=-1.9505), Var(v=0.0357, grad=0.0000), Var(v=-0.0478, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=0.0197, grad=0.0000), Var(v=0.0287, grad=-0.5443), Var(v=-0.0150, grad=0.5074), Var(v=-0.0317, grad=-0.1128), Var(v=-0.0300, grad=-1.7262), Var(v=-0.0298, grad=-1.8049), Var(v=-0.1104, grad=0.0000), Var(v=-0.2209, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=0.0101, grad=0.0000), Var(v=0.1779, grad=-5.6177), Var(v=0.0444, grad=-0.2783), Var(v=-0.0494, grad=0.0000), Var(v=-0.1234, grad=-0.2820), Var(v=-0.0576, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.0742, grad=0.0000), Var(v=0.0780, grad=0.5095), Var(v=-0.0189, grad=0.0000), Var(v=0.1987, grad=-1.1076), Var(v=0.0356, grad=0.0000), Var(v=-0.1697, grad=5.8746), Var(v=0.0346, grad=0.0000), Var(v=0.1538, grad=0.3203), Var(v=0.1920, grad=0.0000), Var(v=0.0382, grad=-0.3981), Var(v=-0.0448, grad=0.0000), Var(v=-0.1053, grad=0.0575), Var(v=-0.0704, grad=-0.4490), Var(v=0.0532, grad=0.0000), Var(v=-0.1832, grad=0.0000), Var(v=0.0082, grad=-1.3966), Var(v=0.1255, grad=0.0000), Var(v=0.1029, grad=-2.3004), Var(v=0.0574, grad=-2.5595), Var(v=0.0560, grad=0.0000), Var(v=0.0133, grad=1.7066), Var(v=-0.0618, grad=-3.9084), Var(v=-0.0914, grad=0.0000), Var(v=-0.0993, grad=1.8581), Var(v=0.0240, grad=0.0000), Var(v=-0.0146, grad=0.0000), Var(v=-0.2539, grad=0.0000), Var(v=-0.0165, grad=0.9468), Var(v=0.1682, grad=-2.4299)], [Var(v=-0.2091, grad=0.2511), Var(v=-0.1165, grad=0.2137), Var(v=-0.0585, grad=0.0000), Var(v=-0.0484, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=-0.1901, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=0.0432, grad=-0.0556), Var(v=-0.0229, grad=-0.1207), Var(v=0.0096, grad=0.1891), Var(v=0.1207, grad=0.1977), Var(v=-0.2380, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=-0.0489, grad=0.0000), Var(v=0.0338, grad=0.0000), Var(v=0.0988, grad=0.0000), Var(v=0.0036, grad=0.0305), Var(v=-0.0117, grad=0.0000), Var(v=-0.0265, grad=-0.4081), Var(v=0.1039, grad=0.0111), Var(v=-0.0933, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.1225, grad=-0.0558), Var(v=0.0409, grad=0.0000), Var(v=-0.1081, grad=0.0000), Var(v=-0.0182, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=0.0281, grad=0.0000), Var(v=0.1569, grad=-0.5223), Var(v=0.0495, grad=0.0000), Var(v=0.0270, grad=0.0436), Var(v=-0.1799, grad=0.0000), Var(v=-0.0385, grad=0.0000), Var(v=0.0276, grad=0.0492), Var(v=0.0418, grad=0.0000), Var(v=-0.1429, grad=0.0000), Var(v=0.0950, grad=0.1530), Var(v=-0.0150, grad=0.0000), Var(v=-0.1462, grad=0.0000), Var(v=-0.0008, grad=0.2804), Var(v=0.0413, grad=0.0000), Var(v=-0.0796, grad=-0.1870), Var(v=-0.1197, grad=0.4282), Var(v=0.0563, grad=0.0000), Var(v=0.0060, grad=-0.2036), Var(v=-0.1062, grad=0.0000), Var(v=-0.0002, grad=0.0000), Var(v=-0.0668, grad=0.0000), Var(v=-0.0695, grad=-0.1037), Var(v=-0.0911, grad=0.0000)], [Var(v=0.0475, grad=-1.3905), Var(v=-0.0086, grad=-1.1835), Var(v=-0.1034, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0964, grad=0.0000), Var(v=-0.0007, grad=0.0000), Var(v=-0.0080, grad=-0.3303), Var(v=-0.0776, grad=0.3078), Var(v=0.1237, grad=-0.0684), Var(v=-0.0199, grad=-1.0474), Var(v=0.2556, grad=-1.0951), Var(v=-0.0176, grad=0.0000), Var(v=0.1284, grad=0.0000), Var(v=0.0594, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0945, grad=-3.4085), Var(v=-0.0482, grad=-0.1688), Var(v=0.0720, grad=0.0000), Var(v=-0.0381, grad=-0.1711), Var(v=-0.0921, grad=0.0000), Var(v=0.1080, grad=0.0000), Var(v=-0.0284, grad=0.0000), Var(v=-0.0661, grad=0.3091), Var(v=0.0603, grad=0.0000), Var(v=-0.0931, grad=-0.6720), Var(v=-0.1504, grad=0.0000), Var(v=-0.0392, grad=3.5644), Var(v=-0.0635, grad=0.0000), Var(v=-0.1679, grad=0.1944), Var(v=-0.0632, grad=0.0000), Var(v=0.1219, grad=-0.2416), Var(v=-0.0906, grad=0.0000), Var(v=0.1228, grad=0.0349), Var(v=0.0072, grad=-0.2724), Var(v=-0.0173, grad=0.0000), Var(v=0.0075, grad=0.0000), Var(v=0.1360, grad=-0.8474), Var(v=0.1090, grad=0.0000), Var(v=0.2031, grad=-1.3958), Var(v=-0.1452, grad=-1.5530), Var(v=-0.1448, grad=0.0000), Var(v=0.0242, grad=1.0355), Var(v=-0.0868, grad=-2.3714), Var(v=-0.0291, grad=0.0000), Var(v=0.2352, grad=1.1274), Var(v=0.0332, grad=0.0000), Var(v=-0.1336, grad=0.0000), Var(v=-0.2128, grad=0.0000), Var(v=-0.0306, grad=0.5745), Var(v=0.0094, grad=-1.4743)], [Var(v=-0.0172, grad=-0.0648), Var(v=0.0406, grad=-0.0552), Var(v=0.0714, grad=0.0000), Var(v=-0.0860, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0190, grad=-0.0154), Var(v=0.1781, grad=0.0144), Var(v=-0.0180, grad=-0.0032), Var(v=-0.0141, grad=-0.0488), Var(v=0.0482, grad=-0.0511), Var(v=-0.1092, grad=0.0000), Var(v=-0.0613, grad=0.0000), Var(v=0.1298, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0170, grad=-0.1589), Var(v=0.0196, grad=-0.0079), Var(v=0.2199, grad=0.0000), Var(v=-0.0290, grad=-0.0080), Var(v=-0.0963, grad=0.0000), Var(v=-0.0333, grad=0.0000), Var(v=-0.0972, grad=0.0000), Var(v=-0.0324, grad=0.0144), Var(v=-0.1003, grad=0.0000), Var(v=-0.1779, grad=-0.0313), Var(v=-0.0075, grad=0.0000), Var(v=0.0473, grad=0.1662), Var(v=-0.1185, grad=0.0000), Var(v=0.0461, grad=0.0091), Var(v=-0.1076, grad=0.0000), Var(v=-0.1256, grad=-0.0113), Var(v=0.1579, grad=0.0000), Var(v=0.0871, grad=0.0016), Var(v=0.0539, grad=-0.0127), Var(v=0.0073, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.1627, grad=-0.0395), Var(v=0.1191, grad=0.0000), Var(v=0.0436, grad=-0.0651), Var(v=0.0143, grad=-0.0724), Var(v=-0.0304, grad=0.0000), Var(v=0.0444, grad=0.0483), Var(v=-0.0709, grad=-0.1106), Var(v=-0.2023, grad=0.0000), Var(v=0.1340, grad=0.0526), Var(v=-0.1599, grad=0.0000), Var(v=-0.0197, grad=0.0000), Var(v=0.0097, grad=0.0000), Var(v=-0.0509, grad=0.0268), Var(v=-0.1684, grad=-0.0687)], [Var(v=0.2279, grad=-1.9233), Var(v=0.1079, grad=-1.6370), Var(v=0.0857, grad=0.0000), Var(v=-0.2246, grad=0.0000), Var(v=-0.0547, grad=0.0000), Var(v=0.0900, grad=0.0000), Var(v=0.0290, grad=-0.4568), Var(v=0.0275, grad=0.4258), Var(v=-0.0170, grad=-0.0947), Var(v=0.0368, grad=-1.4487), Var(v=0.0912, grad=-1.5147), Var(v=0.0375, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=0.0610, grad=0.0000), Var(v=0.1035, grad=-4.7147), Var(v=0.1331, grad=-0.2335), Var(v=-0.0058, grad=0.0000), Var(v=0.0240, grad=-0.2367), Var(v=-0.0431, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.1059, grad=0.0000), Var(v=-0.0059, grad=0.4276), Var(v=0.0723, grad=0.0000), Var(v=0.2853, grad=-0.9296), Var(v=0.1042, grad=0.0000), Var(v=-0.0358, grad=4.9302), Var(v=0.0148, grad=0.0000), Var(v=-0.1463, grad=0.2688), Var(v=-0.0703, grad=0.0000), Var(v=-0.0199, grad=-0.3341), Var(v=-0.0006, grad=0.0000), Var(v=-0.0101, grad=0.0482), Var(v=0.1460, grad=-0.3768), Var(v=-0.1899, grad=0.0000), Var(v=0.0425, grad=0.0000), Var(v=0.0031, grad=-1.1721), Var(v=-0.0573, grad=0.0000), Var(v=-0.0134, grad=-1.9306), Var(v=0.0532, grad=-2.1481), Var(v=0.0035, grad=0.0000), Var(v=0.0537, grad=1.4323), Var(v=0.0863, grad=-3.2801), Var(v=0.2524, grad=0.0000), Var(v=-0.0014, grad=1.5594), Var(v=-0.0919, grad=0.0000), Var(v=-0.1040, grad=0.0000), Var(v=0.0793, grad=0.0000), Var(v=0.0031, grad=0.7946), Var(v=0.0848, grad=-2.0393)], [Var(v=0.0915, grad=-0.1219), Var(v=0.0032, grad=-0.1038), Var(v=-0.0046, grad=0.0000), Var(v=0.0057, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0251, grad=0.0000), Var(v=-0.0285, grad=-0.0290), Var(v=-0.0025, grad=0.0270), Var(v=-0.0940, grad=-0.0060), Var(v=-0.1244, grad=-0.0918), Var(v=-0.0874, grad=-0.0960), Var(v=-0.0206, grad=0.0000), Var(v=-0.1337, grad=0.0000), Var(v=-0.2874, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=-0.0577, grad=-0.2988), Var(v=0.0205, grad=-0.0148), Var(v=-0.0617, grad=0.0000), Var(v=0.0532, grad=-0.0150), Var(v=-0.0680, grad=0.0000), Var(v=0.0307, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=0.0916, grad=0.0271), Var(v=-0.0880, grad=0.0000), Var(v=0.0407, grad=-0.0589), Var(v=0.1206, grad=0.0000), Var(v=-0.0278, grad=0.3125), Var(v=0.0725, grad=0.0000), Var(v=-0.1658, grad=0.0170), Var(v=0.0238, grad=0.0000), Var(v=0.0831, grad=-0.0212), Var(v=0.1146, grad=0.0000), Var(v=-0.1115, grad=0.0031), Var(v=0.1689, grad=-0.0239), Var(v=0.0013, grad=0.0000), Var(v=-0.1077, grad=0.0000), Var(v=0.0070, grad=-0.0743), Var(v=0.0285, grad=0.0000), Var(v=0.1183, grad=-0.1224), Var(v=-0.1162, grad=-0.1362), Var(v=0.1038, grad=0.0000), Var(v=-0.1078, grad=0.0908), Var(v=0.0437, grad=-0.2079), Var(v=-0.0762, grad=0.0000), Var(v=-0.0638, grad=0.0988), Var(v=0.0378, grad=0.0000), Var(v=-0.1536, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0032, grad=0.0504), Var(v=-0.0276, grad=-0.1293)], [Var(v=0.0238, grad=-2.8418), Var(v=0.0825, grad=-2.4188), Var(v=0.0809, grad=0.0000), Var(v=0.1248, grad=0.0000), Var(v=0.2008, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0901, grad=-0.6750), Var(v=-0.0507, grad=0.6292), Var(v=-0.2312, grad=-0.1399), Var(v=0.1213, grad=-2.1406), Var(v=0.1842, grad=-2.2381), Var(v=-0.0403, grad=0.0000), Var(v=0.0246, grad=0.0000), Var(v=-0.0078, grad=0.0000), Var(v=0.0591, grad=0.0000), Var(v=0.2722, grad=-6.9663), Var(v=-0.1817, grad=-0.3451), Var(v=-0.0578, grad=0.0000), Var(v=-0.0057, grad=-0.3497), Var(v=-0.0050, grad=0.0000), Var(v=-0.0611, grad=0.0000), Var(v=-0.0501, grad=0.0000), Var(v=-0.0482, grad=0.6318), Var(v=-0.0807, grad=0.0000), Var(v=0.1183, grad=-1.3735), Var(v=-0.1437, grad=0.0000), Var(v=0.0815, grad=7.2848), Var(v=0.0748, grad=0.0000), Var(v=-0.0496, grad=0.3972), Var(v=0.0482, grad=0.0000), Var(v=0.0556, grad=-0.4937), Var(v=-0.0799, grad=0.0000), Var(v=0.1125, grad=0.0713), Var(v=-0.0774, grad=-0.5568), Var(v=-0.0547, grad=0.0000), Var(v=0.0353, grad=0.0000), Var(v=0.0053, grad=-1.7319), Var(v=-0.1886, grad=0.0000), Var(v=-0.0154, grad=-2.8526), Var(v=0.0511, grad=-3.1740), Var(v=-0.1426, grad=0.0000), Var(v=0.0012, grad=2.1163), Var(v=-0.0605, grad=-4.8466), Var(v=-0.0764, grad=0.0000), Var(v=0.0824, grad=2.3041), Var(v=-0.0156, grad=0.0000), Var(v=-0.0812, grad=0.0000), Var(v=-0.0710, grad=0.0000), Var(v=-0.1284, grad=1.1741), Var(v=0.0389, grad=-3.0132)], [Var(v=-0.1603, grad=-0.4424), Var(v=-0.0691, grad=-0.3765), Var(v=-0.0080, grad=0.0000), Var(v=-0.0279, grad=0.0000), Var(v=-0.1489, grad=0.0000), Var(v=0.0016, grad=0.0000), Var(v=-0.0313, grad=-0.1051), Var(v=-0.1120, grad=0.0979), Var(v=-0.1001, grad=-0.0218), Var(v=-0.0245, grad=-0.3332), Var(v=-0.1117, grad=-0.3484), Var(v=0.0670, grad=0.0000), Var(v=-0.1300, grad=0.0000), Var(v=0.0996, grad=0.0000), Var(v=-0.0229, grad=0.0000), Var(v=-0.0565, grad=-1.0844), Var(v=0.1031, grad=-0.0537), Var(v=-0.0106, grad=0.0000), Var(v=0.0676, grad=-0.0544), Var(v=-0.0324, grad=0.0000), Var(v=0.0089, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.0668, grad=0.0983), Var(v=-0.0381, grad=0.0000), Var(v=-0.2099, grad=-0.2138), Var(v=0.0322, grad=0.0000), Var(v=0.0926, grad=1.1340), Var(v=0.0877, grad=0.0000), Var(v=-0.2138, grad=0.0618), Var(v=0.0221, grad=0.0000), Var(v=-0.0084, grad=-0.0768), Var(v=-0.0747, grad=0.0000), Var(v=-0.0869, grad=0.0111), Var(v=-0.0058, grad=-0.0867), Var(v=0.1365, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0726, grad=-0.2696), Var(v=-0.0749, grad=0.0000), Var(v=0.1040, grad=-0.4440), Var(v=-0.1439, grad=-0.4941), Var(v=0.0921, grad=0.0000), Var(v=-0.1414, grad=0.3294), Var(v=-0.0303, grad=-0.7544), Var(v=0.0450, grad=0.0000), Var(v=-0.0868, grad=0.3587), Var(v=0.1065, grad=0.0000), Var(v=-0.0156, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=0.1195, grad=0.1828), Var(v=0.3582, grad=-0.4691)], [Var(v=-0.0357, grad=0.1627), Var(v=-0.1463, grad=0.1385), Var(v=-0.0673, grad=0.0000), Var(v=0.1058, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0470, grad=0.0000), Var(v=0.0576, grad=-0.0360), Var(v=0.1235, grad=-0.0782), Var(v=-0.1070, grad=0.1226), Var(v=-0.1568, grad=0.1281), Var(v=0.0152, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1168, grad=0.0000), Var(v=0.0565, grad=0.0000), Var(v=-0.0386, grad=0.0000), Var(v=0.0797, grad=0.0198), Var(v=-0.0232, grad=0.0000), Var(v=0.2352, grad=-0.2645), Var(v=0.1019, grad=0.0072), Var(v=0.0803, grad=0.0000), Var(v=0.0559, grad=0.0000), Var(v=0.0315, grad=-0.0362), Var(v=-0.0357, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.1548, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.0639, grad=0.0000), Var(v=-0.1322, grad=-0.3385), Var(v=-0.1196, grad=0.0000), Var(v=0.0574, grad=0.0283), Var(v=0.2020, grad=0.0000), Var(v=0.2109, grad=0.0000), Var(v=0.1282, grad=0.0319), Var(v=-0.1079, grad=0.0000), Var(v=0.0933, grad=0.0000), Var(v=0.0761, grad=0.0992), Var(v=0.1385, grad=0.0000), Var(v=0.0876, grad=0.0000), Var(v=0.1213, grad=0.1817), Var(v=0.1716, grad=0.0000), Var(v=0.1373, grad=-0.1212), Var(v=-0.0898, grad=0.2775), Var(v=-0.3042, grad=0.0000), Var(v=-0.0914, grad=-0.1319), Var(v=0.0441, grad=0.0000), Var(v=-0.1991, grad=0.0000), Var(v=0.0273, grad=0.0000), Var(v=-0.1385, grad=-0.0672), Var(v=-0.0137, grad=0.0000)], [Var(v=-0.1005, grad=0.1680), Var(v=0.0181, grad=0.1430), Var(v=-0.0127, grad=0.0000), Var(v=0.1999, grad=0.0000), Var(v=-0.0897, grad=0.0000), Var(v=-0.0076, grad=0.0000), Var(v=0.0267, grad=0.0000), Var(v=0.1177, grad=-0.0372), Var(v=-0.0508, grad=-0.0808), Var(v=0.0303, grad=0.1266), Var(v=0.0683, grad=0.1323), Var(v=-0.1520, grad=0.0000), Var(v=0.0177, grad=0.0000), Var(v=0.1819, grad=0.0000), Var(v=0.0069, grad=0.0000), Var(v=0.0539, grad=0.0000), Var(v=-0.0465, grad=0.0204), Var(v=0.0837, grad=0.0000), Var(v=-0.1267, grad=-0.2731), Var(v=0.0325, grad=0.0074), Var(v=0.0456, grad=0.0000), Var(v=0.1214, grad=0.0000), Var(v=0.0433, grad=-0.0374), Var(v=-0.0056, grad=0.0000), Var(v=-0.0281, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0781, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=0.0877, grad=-0.3496), Var(v=-0.1031, grad=0.0000), Var(v=-0.1386, grad=0.0292), Var(v=0.0627, grad=0.0000), Var(v=0.0982, grad=0.0000), Var(v=0.1567, grad=0.0329), Var(v=0.0466, grad=0.0000), Var(v=-0.0339, grad=0.0000), Var(v=-0.0252, grad=0.1024), Var(v=-0.0968, grad=0.0000), Var(v=0.0136, grad=0.0000), Var(v=-0.0310, grad=0.1877), Var(v=0.0200, grad=0.0000), Var(v=0.0476, grad=-0.1251), Var(v=-0.0818, grad=0.2866), Var(v=0.0750, grad=0.0000), Var(v=-0.0226, grad=-0.1362), Var(v=0.0121, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0067, grad=-0.0694), Var(v=-0.0006, grad=0.0000)], [Var(v=-0.0581, grad=0.0038), Var(v=0.1351, grad=0.0032), Var(v=0.0019, grad=0.0000), Var(v=0.1467, grad=0.0000), Var(v=-0.1703, grad=0.0000), Var(v=0.0694, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.0755, grad=-0.0008), Var(v=0.1026, grad=-0.0018), Var(v=-0.0836, grad=0.0029), Var(v=0.0724, grad=0.0030), Var(v=-0.1760, grad=0.0000), Var(v=0.1511, grad=0.0000), Var(v=-0.0570, grad=0.0000), Var(v=0.0858, grad=0.0000), Var(v=0.1266, grad=0.0000), Var(v=0.0130, grad=0.0005), Var(v=-0.1708, grad=0.0000), Var(v=0.0071, grad=-0.0062), Var(v=0.1116, grad=0.0002), Var(v=-0.0269, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.1170, grad=-0.0008), Var(v=-0.0785, grad=0.0000), Var(v=0.0451, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0238, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=-0.0727, grad=-0.0079), Var(v=-0.0361, grad=0.0000), Var(v=0.0046, grad=0.0007), Var(v=-0.0185, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0237, grad=0.0007), Var(v=-0.1411, grad=0.0000), Var(v=-0.1114, grad=0.0000), Var(v=-0.0273, grad=0.0023), Var(v=0.1794, grad=0.0000), Var(v=0.1429, grad=0.0000), Var(v=0.2494, grad=0.0042), Var(v=0.0980, grad=0.0000), Var(v=-0.1321, grad=-0.0028), Var(v=-0.1716, grad=0.0065), Var(v=-0.0970, grad=0.0000), Var(v=-0.1031, grad=-0.0031), Var(v=-0.0453, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=0.0500, grad=0.0000), Var(v=0.0073, grad=-0.0016), Var(v=-0.1355, grad=0.0000)], [Var(v=0.0377, grad=-0.2456), Var(v=0.1245, grad=-0.2091), Var(v=0.0014, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=-0.1973, grad=0.0000), Var(v=-0.0286, grad=0.0000), Var(v=-0.1848, grad=-0.0583), Var(v=0.0290, grad=0.0544), Var(v=-0.1807, grad=-0.0121), Var(v=0.0384, grad=-0.1850), Var(v=-0.1705, grad=-0.1935), Var(v=-0.1822, grad=0.0000), Var(v=0.1642, grad=0.0000), Var(v=0.0739, grad=0.0000), Var(v=-0.1425, grad=0.0000), Var(v=-0.1681, grad=-0.6021), Var(v=-0.0971, grad=-0.0298), Var(v=0.0604, grad=0.0000), Var(v=-0.1537, grad=-0.0302), Var(v=-0.0924, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=0.0153, grad=0.0000), Var(v=0.0866, grad=0.0546), Var(v=-0.1542, grad=0.0000), Var(v=0.1174, grad=-0.1187), Var(v=-0.0372, grad=0.0000), Var(v=-0.0065, grad=0.6297), Var(v=0.0034, grad=0.0000), Var(v=-0.0836, grad=0.0343), Var(v=-0.0334, grad=0.0000), Var(v=-0.0162, grad=-0.0427), Var(v=0.2207, grad=0.0000), Var(v=-0.1544, grad=0.0062), Var(v=-0.0044, grad=-0.0481), Var(v=0.0104, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0450, grad=-0.1497), Var(v=0.2960, grad=0.0000), Var(v=0.0655, grad=-0.2466), Var(v=-0.0784, grad=-0.2744), Var(v=-0.1599, grad=0.0000), Var(v=0.0050, grad=0.1829), Var(v=-0.0595, grad=-0.4189), Var(v=0.0693, grad=0.0000), Var(v=0.1302, grad=0.1992), Var(v=0.1107, grad=0.0000), Var(v=0.0028, grad=0.0000), Var(v=0.0761, grad=0.0000), Var(v=-0.0652, grad=0.1015), Var(v=0.1737, grad=-0.2605)], [Var(v=0.0871, grad=0.1509), Var(v=0.1439, grad=0.1284), Var(v=0.1109, grad=0.0000), Var(v=-0.0454, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0280, grad=0.0000), Var(v=0.1577, grad=0.0000), Var(v=0.0216, grad=-0.0334), Var(v=0.1322, grad=-0.0725), Var(v=-0.0597, grad=0.1137), Var(v=0.1185, grad=0.1188), Var(v=0.1125, grad=0.0000), Var(v=-0.0833, grad=0.0000), Var(v=0.1944, grad=0.0000), Var(v=0.1960, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=-0.0385, grad=0.0183), Var(v=-0.0211, grad=0.0000), Var(v=-0.1800, grad=-0.2453), Var(v=0.0013, grad=0.0067), Var(v=-0.0931, grad=0.0000), Var(v=-0.0235, grad=0.0000), Var(v=0.0097, grad=-0.0335), Var(v=-0.1651, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0500, grad=0.0000), Var(v=0.0670, grad=-0.3140), Var(v=-0.0227, grad=0.0000), Var(v=0.0817, grad=0.0262), Var(v=-0.0644, grad=0.0000), Var(v=0.0834, grad=0.0000), Var(v=0.0577, grad=0.0296), Var(v=-0.1040, grad=0.0000), Var(v=-0.0875, grad=0.0000), Var(v=0.0892, grad=0.0920), Var(v=-0.0046, grad=0.0000), Var(v=-0.1068, grad=0.0000), Var(v=-0.0467, grad=0.1685), Var(v=0.1555, grad=0.0000), Var(v=-0.0837, grad=-0.1124), Var(v=0.0815, grad=0.2574), Var(v=0.1532, grad=0.0000), Var(v=-0.1286, grad=-0.1224), Var(v=0.0984, grad=0.0000), Var(v=0.0787, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0952, grad=-0.0623), Var(v=-0.0116, grad=0.0000)]] Biases: [Var(v=-0.3184, grad=31.8404), Var(v=-0.2710, grad=27.1002), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.1734, grad=-17.3399), Var(v=0.0705, grad=-7.0493), Var(v=0.5842, grad=-58.4178), Var(v=-0.2398, grad=23.9839), Var(v=-0.2508, grad=25.0765), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=1.9913, grad=-199.1327), Var(v=-0.0387, grad=3.8662), Var(v=0.0000, grad=0.0000), Var(v=1.9142, grad=-191.4219), Var(v=-0.0214, grad=2.1381), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0708, grad=-7.0785), Var(v=0.0000, grad=0.0000), Var(v=0.3127, grad=-31.2711), Var(v=0.0000, grad=0.0000), Var(v=-1.9905, grad=199.0471), Var(v=0.0000, grad=0.0000), Var(v=2.1000, grad=-209.9952), Var(v=0.0000, grad=0.0000), Var(v=-0.0553, grad=5.5313), Var(v=0.0000, grad=0.0000), Var(v=-0.0161, grad=1.6108), Var(v=-0.0624, grad=6.2379), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.1940, grad=19.4048), Var(v=0.0000, grad=0.0000), Var(v=0.7357, grad=-73.5689), Var(v=-0.3556, grad=35.5619), Var(v=0.0000, grad=0.0000), Var(v=0.2371, grad=-23.7113), Var(v=-0.5430, grad=54.3025), Var(v=0.0000, grad=0.0000), Var(v=0.2582, grad=-25.8159), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.1315, grad=-13.1544), Var(v=0.7307, grad=-73.0668)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=-0.1052, grad=18.7372)], [Var(v=0.1308, grad=-6.0868)], [Var(v=0.0642, grad=0.0000)], [Var(v=-0.1283, grad=0.0000)], [Var(v=-0.2168, grad=0.0000)], [Var(v=0.3005, grad=0.0000)], [Var(v=0.0281, grad=-0.6340)], [Var(v=-0.0727, grad=5.4561)], [Var(v=-0.0961, grad=5.6571)], [Var(v=0.0782, grad=-1.6308)], [Var(v=0.1452, grad=-8.0501)], [Var(v=0.1217, grad=0.0000)], [Var(v=-0.0547, grad=0.0000)], [Var(v=-0.1258, grad=0.0000)], [Var(v=-0.0202, grad=0.0000)], [Var(v=0.2573, grad=-7.4380)], [Var(v=-0.0296, grad=3.9578)], [Var(v=0.2897, grad=0.0000)], [Var(v=-0.1630, grad=2.9441)], [Var(v=0.0148, grad=0.0051)], [Var(v=0.0060, grad=0.0000)], [Var(v=0.1579, grad=0.0000)], [Var(v=-0.0415, grad=2.3254)], [Var(v=0.1643, grad=0.0000)], [Var(v=0.1547, grad=-11.5818)], [Var(v=-0.0425, grad=0.0000)], [Var(v=-0.1739, grad=-2.2019)], [Var(v=0.1258, grad=0.0000)], [Var(v=-0.2247, grad=5.3765)], [Var(v=-0.1015, grad=0.0000)], [Var(v=0.0275, grad=-1.3214)], [Var(v=0.1176, grad=0.0000)], [Var(v=-0.0141, grad=-0.0039)], [Var(v=-0.0151, grad=3.1152)], [Var(v=-0.1154, grad=0.0000)], [Var(v=0.0503, grad=0.0000)], [Var(v=0.0395, grad=1.0521)], [Var(v=-0.0232, grad=0.0000)], [Var(v=0.1099, grad=-3.1417)], [Var(v=0.0425, grad=4.9239)], [Var(v=-0.0399, grad=0.0000)], [Var(v=-0.0569, grad=-0.4231)], [Var(v=0.0310, grad=10.9108)], [Var(v=0.1351, grad=0.0000)], [Var(v=-0.0064, grad=-6.0248)], [Var(v=-0.1731, grad=0.0000)], [Var(v=0.1245, grad=0.0000)], [Var(v=0.0025, grad=0.0000)], [Var(v=-0.1061, grad=7.2136)], [Var(v=0.1327, grad=-0.8595)]] Biases: [Var(v=-12.9194, grad=1291.9406)]\n",
      "\n",
      "Network after zeroing gradients:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=0.0456, grad=0.0000), Var(v=-0.1100, grad=0.0000), Var(v=0.2939, grad=0.0000), Var(v=-0.1484, grad=0.0000), Var(v=0.1207, grad=0.0000), Var(v=-0.0581, grad=0.0000), Var(v=0.2506, grad=0.0000), Var(v=0.0189, grad=0.0000), Var(v=0.2540, grad=0.0000), Var(v=-0.0132, grad=0.0000), Var(v=-0.0982, grad=0.0000), Var(v=-0.0968, grad=0.0000), Var(v=0.0035, grad=0.0000), Var(v=-0.0335, grad=0.0000), Var(v=-0.0710, grad=0.0000)]] Biases: [Var(v=0.0020, grad=0.0000), Var(v=0.0066, grad=0.0000), Var(v=0.0452, grad=0.0000), Var(v=0.0222, grad=0.0000), Var(v=0.0011, grad=0.0000), Var(v=-0.0219, grad=0.0000), Var(v=0.0198, grad=0.0000), Var(v=-0.0048, grad=0.0000), Var(v=0.0018, grad=0.0000), Var(v=-0.0225, grad=0.0000), Var(v=0.0197, grad=0.0000), Var(v=0.0081, grad=0.0000), Var(v=-0.0146, grad=0.0000), Var(v=-0.0325, grad=0.0000), Var(v=-0.0346, grad=0.0000)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=-0.0013, grad=0.0000), Var(v=0.0507, grad=0.0000), Var(v=-0.1077, grad=0.0000), Var(v=-0.2264, grad=0.0000), Var(v=-0.0346, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=-0.0264, grad=0.0000), Var(v=0.1137, grad=0.0000), Var(v=0.1003, grad=0.0000), Var(v=0.0128, grad=0.0000), Var(v=0.0127, grad=0.0000), Var(v=-0.0974, grad=0.0000), Var(v=-0.0132, grad=0.0000), Var(v=-0.0712, grad=0.0000), Var(v=-0.0534, grad=0.0000), Var(v=0.0693, grad=0.0000), Var(v=0.0667, grad=0.0000), Var(v=-0.0551, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0171, grad=0.0000), Var(v=-0.1395, grad=0.0000), Var(v=-0.0569, grad=0.0000), Var(v=0.1567, grad=0.0000), Var(v=-0.0133, grad=0.0000), Var(v=-0.0026, grad=0.0000), Var(v=-0.1238, grad=0.0000), Var(v=-0.1563, grad=0.0000), Var(v=-0.1657, grad=0.0000), Var(v=0.1940, grad=0.0000), Var(v=-0.0843, grad=0.0000), Var(v=0.1136, grad=0.0000), Var(v=-0.1430, grad=0.0000), Var(v=-0.0332, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=-0.0009, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.1012, grad=0.0000), Var(v=-0.1340, grad=0.0000), Var(v=0.0352, grad=0.0000), Var(v=0.1271, grad=0.0000), Var(v=-0.1506, grad=0.0000), Var(v=0.1386, grad=0.0000), Var(v=0.1411, grad=0.0000), Var(v=-0.0756, grad=0.0000), Var(v=0.0296, grad=0.0000), Var(v=-0.0286, grad=0.0000), Var(v=-0.0717, grad=0.0000), Var(v=-0.0855, grad=0.0000), Var(v=0.1732, grad=0.0000), Var(v=-0.0604, grad=0.0000)], [Var(v=0.0566, grad=0.0000), Var(v=-0.2060, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=-0.0458, grad=0.0000), Var(v=-0.0820, grad=0.0000), Var(v=-0.1614, grad=0.0000), Var(v=0.0329, grad=0.0000), Var(v=-0.0698, grad=0.0000), Var(v=0.0687, grad=0.0000), Var(v=-0.0347, grad=0.0000), Var(v=-0.0488, grad=0.0000), Var(v=0.0233, grad=0.0000), Var(v=-0.0895, grad=0.0000), Var(v=-0.0166, grad=0.0000), Var(v=-0.1834, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=-0.1160, grad=0.0000), Var(v=-0.0607, grad=0.0000), Var(v=-0.0221, grad=0.0000), Var(v=0.0172, grad=0.0000), Var(v=0.0504, grad=0.0000), Var(v=0.0674, grad=0.0000), Var(v=-0.1240, grad=0.0000), Var(v=0.1373, grad=0.0000), Var(v=-0.0483, grad=0.0000), Var(v=0.0671, grad=0.0000), Var(v=-0.0646, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=0.0521, grad=0.0000), Var(v=0.1182, grad=0.0000), Var(v=0.0744, grad=0.0000), Var(v=0.0199, grad=0.0000), Var(v=0.0170, grad=0.0000), Var(v=-0.0247, grad=0.0000), Var(v=-0.0693, grad=0.0000), Var(v=-0.1484, grad=0.0000), Var(v=0.0273, grad=0.0000), Var(v=0.0517, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0172, grad=0.0000), Var(v=0.0114, grad=0.0000), Var(v=-0.0677, grad=0.0000), Var(v=0.0449, grad=0.0000), Var(v=-0.0078, grad=0.0000), Var(v=-0.0122, grad=0.0000), Var(v=-0.1593, grad=0.0000), Var(v=0.1734, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=0.1323, grad=0.0000), Var(v=0.0147, grad=0.0000)], [Var(v=0.1027, grad=0.0000), Var(v=0.1235, grad=0.0000), Var(v=0.0357, grad=0.0000), Var(v=-0.0478, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=0.0197, grad=0.0000), Var(v=0.0287, grad=0.0000), Var(v=-0.0150, grad=0.0000), Var(v=-0.0317, grad=0.0000), Var(v=-0.0300, grad=0.0000), Var(v=-0.0298, grad=0.0000), Var(v=-0.1104, grad=0.0000), Var(v=-0.2209, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=0.0101, grad=0.0000), Var(v=0.1779, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=-0.0494, grad=0.0000), Var(v=-0.1234, grad=0.0000), Var(v=-0.0576, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.0742, grad=0.0000), Var(v=0.0780, grad=0.0000), Var(v=-0.0189, grad=0.0000), Var(v=0.1987, grad=0.0000), Var(v=0.0356, grad=0.0000), Var(v=-0.1697, grad=0.0000), Var(v=0.0346, grad=0.0000), Var(v=0.1538, grad=0.0000), Var(v=0.1920, grad=0.0000), Var(v=0.0382, grad=0.0000), Var(v=-0.0448, grad=0.0000), Var(v=-0.1053, grad=0.0000), Var(v=-0.0704, grad=0.0000), Var(v=0.0532, grad=0.0000), Var(v=-0.1832, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.1255, grad=0.0000), Var(v=0.1029, grad=0.0000), Var(v=0.0574, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=0.0133, grad=0.0000), Var(v=-0.0618, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0993, grad=0.0000), Var(v=0.0240, grad=0.0000), Var(v=-0.0146, grad=0.0000), Var(v=-0.2539, grad=0.0000), Var(v=-0.0165, grad=0.0000), Var(v=0.1682, grad=0.0000)], [Var(v=-0.2091, grad=0.0000), Var(v=-0.1165, grad=0.0000), Var(v=-0.0585, grad=0.0000), Var(v=-0.0484, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=-0.1901, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=0.0432, grad=0.0000), Var(v=-0.0229, grad=0.0000), Var(v=0.0096, grad=0.0000), Var(v=0.1207, grad=0.0000), Var(v=-0.2380, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=-0.0489, grad=0.0000), Var(v=0.0338, grad=0.0000), Var(v=0.0988, grad=0.0000), Var(v=0.0036, grad=0.0000), Var(v=-0.0117, grad=0.0000), Var(v=-0.0265, grad=0.0000), Var(v=0.1039, grad=0.0000), Var(v=-0.0933, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.1225, grad=0.0000), Var(v=0.0409, grad=0.0000), Var(v=-0.1081, grad=0.0000), Var(v=-0.0182, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=0.0281, grad=0.0000), Var(v=0.1569, grad=0.0000), Var(v=0.0495, grad=0.0000), Var(v=0.0270, grad=0.0000), Var(v=-0.1799, grad=0.0000), Var(v=-0.0385, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.0418, grad=0.0000), Var(v=-0.1429, grad=0.0000), Var(v=0.0950, grad=0.0000), Var(v=-0.0150, grad=0.0000), Var(v=-0.1462, grad=0.0000), Var(v=-0.0008, grad=0.0000), Var(v=0.0413, grad=0.0000), Var(v=-0.0796, grad=0.0000), Var(v=-0.1197, grad=0.0000), Var(v=0.0563, grad=0.0000), Var(v=0.0060, grad=0.0000), Var(v=-0.1062, grad=0.0000), Var(v=-0.0002, grad=0.0000), Var(v=-0.0668, grad=0.0000), Var(v=-0.0695, grad=0.0000), Var(v=-0.0911, grad=0.0000)], [Var(v=0.0475, grad=0.0000), Var(v=-0.0086, grad=0.0000), Var(v=-0.1034, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0964, grad=0.0000), Var(v=-0.0007, grad=0.0000), Var(v=-0.0080, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=0.1237, grad=0.0000), Var(v=-0.0199, grad=0.0000), Var(v=0.2556, grad=0.0000), Var(v=-0.0176, grad=0.0000), Var(v=0.1284, grad=0.0000), Var(v=0.0594, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0945, grad=0.0000), Var(v=-0.0482, grad=0.0000), Var(v=0.0720, grad=0.0000), Var(v=-0.0381, grad=0.0000), Var(v=-0.0921, grad=0.0000), Var(v=0.1080, grad=0.0000), Var(v=-0.0284, grad=0.0000), Var(v=-0.0661, grad=0.0000), Var(v=0.0603, grad=0.0000), Var(v=-0.0931, grad=0.0000), Var(v=-0.1504, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=-0.0635, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=-0.0632, grad=0.0000), Var(v=0.1219, grad=0.0000), Var(v=-0.0906, grad=0.0000), Var(v=0.1228, grad=0.0000), Var(v=0.0072, grad=0.0000), Var(v=-0.0173, grad=0.0000), Var(v=0.0075, grad=0.0000), Var(v=0.1360, grad=0.0000), Var(v=0.1090, grad=0.0000), Var(v=0.2031, grad=0.0000), Var(v=-0.1452, grad=0.0000), Var(v=-0.1448, grad=0.0000), Var(v=0.0242, grad=0.0000), Var(v=-0.0868, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=0.2352, grad=0.0000), Var(v=0.0332, grad=0.0000), Var(v=-0.1336, grad=0.0000), Var(v=-0.2128, grad=0.0000), Var(v=-0.0306, grad=0.0000), Var(v=0.0094, grad=0.0000)], [Var(v=-0.0172, grad=0.0000), Var(v=0.0406, grad=0.0000), Var(v=0.0714, grad=0.0000), Var(v=-0.0860, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0190, grad=0.0000), Var(v=0.1781, grad=0.0000), Var(v=-0.0180, grad=0.0000), Var(v=-0.0141, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0613, grad=0.0000), Var(v=0.1298, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0170, grad=0.0000), Var(v=0.0196, grad=0.0000), Var(v=0.2199, grad=0.0000), Var(v=-0.0290, grad=0.0000), Var(v=-0.0963, grad=0.0000), Var(v=-0.0333, grad=0.0000), Var(v=-0.0972, grad=0.0000), Var(v=-0.0324, grad=0.0000), Var(v=-0.1003, grad=0.0000), Var(v=-0.1779, grad=0.0000), Var(v=-0.0075, grad=0.0000), Var(v=0.0473, grad=0.0000), Var(v=-0.1185, grad=0.0000), Var(v=0.0461, grad=0.0000), Var(v=-0.1076, grad=0.0000), Var(v=-0.1256, grad=0.0000), Var(v=0.1579, grad=0.0000), Var(v=0.0871, grad=0.0000), Var(v=0.0539, grad=0.0000), Var(v=0.0073, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.1627, grad=0.0000), Var(v=0.1191, grad=0.0000), Var(v=0.0436, grad=0.0000), Var(v=0.0143, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=-0.0709, grad=0.0000), Var(v=-0.2023, grad=0.0000), Var(v=0.1340, grad=0.0000), Var(v=-0.1599, grad=0.0000), Var(v=-0.0197, grad=0.0000), Var(v=0.0097, grad=0.0000), Var(v=-0.0509, grad=0.0000), Var(v=-0.1684, grad=0.0000)], [Var(v=0.2279, grad=0.0000), Var(v=0.1079, grad=0.0000), Var(v=0.0857, grad=0.0000), Var(v=-0.2246, grad=0.0000), Var(v=-0.0547, grad=0.0000), Var(v=0.0900, grad=0.0000), Var(v=0.0290, grad=0.0000), Var(v=0.0275, grad=0.0000), Var(v=-0.0170, grad=0.0000), Var(v=0.0368, grad=0.0000), Var(v=0.0912, grad=0.0000), Var(v=0.0375, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=0.0610, grad=0.0000), Var(v=0.1035, grad=0.0000), Var(v=0.1331, grad=0.0000), Var(v=-0.0058, grad=0.0000), Var(v=0.0240, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.1059, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.0723, grad=0.0000), Var(v=0.2853, grad=0.0000), Var(v=0.1042, grad=0.0000), Var(v=-0.0358, grad=0.0000), Var(v=0.0148, grad=0.0000), Var(v=-0.1463, grad=0.0000), Var(v=-0.0703, grad=0.0000), Var(v=-0.0199, grad=0.0000), Var(v=-0.0006, grad=0.0000), Var(v=-0.0101, grad=0.0000), Var(v=0.1460, grad=0.0000), Var(v=-0.1899, grad=0.0000), Var(v=0.0425, grad=0.0000), Var(v=0.0031, grad=0.0000), Var(v=-0.0573, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=0.0532, grad=0.0000), Var(v=0.0035, grad=0.0000), Var(v=0.0537, grad=0.0000), Var(v=0.0863, grad=0.0000), Var(v=0.2524, grad=0.0000), Var(v=-0.0014, grad=0.0000), Var(v=-0.0919, grad=0.0000), Var(v=-0.1040, grad=0.0000), Var(v=0.0793, grad=0.0000), Var(v=0.0031, grad=0.0000), Var(v=0.0848, grad=0.0000)], [Var(v=0.0915, grad=0.0000), Var(v=0.0032, grad=0.0000), Var(v=-0.0046, grad=0.0000), Var(v=0.0057, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0251, grad=0.0000), Var(v=-0.0285, grad=0.0000), Var(v=-0.0025, grad=0.0000), Var(v=-0.0940, grad=0.0000), Var(v=-0.1244, grad=0.0000), Var(v=-0.0874, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=-0.1337, grad=0.0000), Var(v=-0.2874, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=-0.0577, grad=0.0000), Var(v=0.0205, grad=0.0000), Var(v=-0.0617, grad=0.0000), Var(v=0.0532, grad=0.0000), Var(v=-0.0680, grad=0.0000), Var(v=0.0307, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=0.0916, grad=0.0000), Var(v=-0.0880, grad=0.0000), Var(v=0.0407, grad=0.0000), Var(v=0.1206, grad=0.0000), Var(v=-0.0278, grad=0.0000), Var(v=0.0725, grad=0.0000), Var(v=-0.1658, grad=0.0000), Var(v=0.0238, grad=0.0000), Var(v=0.0831, grad=0.0000), Var(v=0.1146, grad=0.0000), Var(v=-0.1115, grad=0.0000), Var(v=0.1689, grad=0.0000), Var(v=0.0013, grad=0.0000), Var(v=-0.1077, grad=0.0000), Var(v=0.0070, grad=0.0000), Var(v=0.0285, grad=0.0000), Var(v=0.1183, grad=0.0000), Var(v=-0.1162, grad=0.0000), Var(v=0.1038, grad=0.0000), Var(v=-0.1078, grad=0.0000), Var(v=0.0437, grad=0.0000), Var(v=-0.0762, grad=0.0000), Var(v=-0.0638, grad=0.0000), Var(v=0.0378, grad=0.0000), Var(v=-0.1536, grad=0.0000), Var(v=-0.1043, grad=0.0000), Var(v=0.0032, grad=0.0000), Var(v=-0.0276, grad=0.0000)], [Var(v=0.0238, grad=0.0000), Var(v=0.0825, grad=0.0000), Var(v=0.0809, grad=0.0000), Var(v=0.1248, grad=0.0000), Var(v=0.2008, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0901, grad=0.0000), Var(v=-0.0507, grad=0.0000), Var(v=-0.2312, grad=0.0000), Var(v=0.1213, grad=0.0000), Var(v=0.1842, grad=0.0000), Var(v=-0.0403, grad=0.0000), Var(v=0.0246, grad=0.0000), Var(v=-0.0078, grad=0.0000), Var(v=0.0591, grad=0.0000), Var(v=0.2722, grad=0.0000), Var(v=-0.1817, grad=0.0000), Var(v=-0.0578, grad=0.0000), Var(v=-0.0057, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=-0.0611, grad=0.0000), Var(v=-0.0501, grad=0.0000), Var(v=-0.0482, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1183, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=0.0815, grad=0.0000), Var(v=0.0748, grad=0.0000), Var(v=-0.0496, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=0.0556, grad=0.0000), Var(v=-0.0799, grad=0.0000), Var(v=0.1125, grad=0.0000), Var(v=-0.0774, grad=0.0000), Var(v=-0.0547, grad=0.0000), Var(v=0.0353, grad=0.0000), Var(v=0.0053, grad=0.0000), Var(v=-0.1886, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=0.0511, grad=0.0000), Var(v=-0.1426, grad=0.0000), Var(v=0.0012, grad=0.0000), Var(v=-0.0605, grad=0.0000), Var(v=-0.0764, grad=0.0000), Var(v=0.0824, grad=0.0000), Var(v=-0.0156, grad=0.0000), Var(v=-0.0812, grad=0.0000), Var(v=-0.0710, grad=0.0000), Var(v=-0.1284, grad=0.0000), Var(v=0.0389, grad=0.0000)], [Var(v=-0.1603, grad=0.0000), Var(v=-0.0691, grad=0.0000), Var(v=-0.0080, grad=0.0000), Var(v=-0.0279, grad=0.0000), Var(v=-0.1489, grad=0.0000), Var(v=0.0016, grad=0.0000), Var(v=-0.0313, grad=0.0000), Var(v=-0.1120, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=-0.0245, grad=0.0000), Var(v=-0.1117, grad=0.0000), Var(v=0.0670, grad=0.0000), Var(v=-0.1300, grad=0.0000), Var(v=0.0996, grad=0.0000), Var(v=-0.0229, grad=0.0000), Var(v=-0.0565, grad=0.0000), Var(v=0.1031, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0676, grad=0.0000), Var(v=-0.0324, grad=0.0000), Var(v=0.0089, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.0668, grad=0.0000), Var(v=-0.0381, grad=0.0000), Var(v=-0.2099, grad=0.0000), Var(v=0.0322, grad=0.0000), Var(v=0.0926, grad=0.0000), Var(v=0.0877, grad=0.0000), Var(v=-0.2138, grad=0.0000), Var(v=0.0221, grad=0.0000), Var(v=-0.0084, grad=0.0000), Var(v=-0.0747, grad=0.0000), Var(v=-0.0869, grad=0.0000), Var(v=-0.0058, grad=0.0000), Var(v=0.1365, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0726, grad=0.0000), Var(v=-0.0749, grad=0.0000), Var(v=0.1040, grad=0.0000), Var(v=-0.1439, grad=0.0000), Var(v=0.0921, grad=0.0000), Var(v=-0.1414, grad=0.0000), Var(v=-0.0303, grad=0.0000), Var(v=0.0450, grad=0.0000), Var(v=-0.0868, grad=0.0000), Var(v=0.1065, grad=0.0000), Var(v=-0.0156, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=0.1195, grad=0.0000), Var(v=0.3582, grad=0.0000)], [Var(v=-0.0357, grad=0.0000), Var(v=-0.1463, grad=0.0000), Var(v=-0.0673, grad=0.0000), Var(v=0.1058, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0470, grad=0.0000), Var(v=0.0576, grad=0.0000), Var(v=0.1235, grad=0.0000), Var(v=-0.1070, grad=0.0000), Var(v=-0.1568, grad=0.0000), Var(v=0.0152, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1168, grad=0.0000), Var(v=0.0565, grad=0.0000), Var(v=-0.0386, grad=0.0000), Var(v=0.0797, grad=0.0000), Var(v=-0.0232, grad=0.0000), Var(v=0.2352, grad=0.0000), Var(v=0.1019, grad=0.0000), Var(v=0.0803, grad=0.0000), Var(v=0.0559, grad=0.0000), Var(v=0.0315, grad=0.0000), Var(v=-0.0357, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.1548, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.0639, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=-0.1196, grad=0.0000), Var(v=0.0574, grad=0.0000), Var(v=0.2020, grad=0.0000), Var(v=0.2109, grad=0.0000), Var(v=0.1282, grad=0.0000), Var(v=-0.1079, grad=0.0000), Var(v=0.0933, grad=0.0000), Var(v=0.0761, grad=0.0000), Var(v=0.1385, grad=0.0000), Var(v=0.0876, grad=0.0000), Var(v=0.1213, grad=0.0000), Var(v=0.1716, grad=0.0000), Var(v=0.1373, grad=0.0000), Var(v=-0.0898, grad=0.0000), Var(v=-0.3042, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=0.0441, grad=0.0000), Var(v=-0.1991, grad=0.0000), Var(v=0.0273, grad=0.0000), Var(v=-0.1385, grad=0.0000), Var(v=-0.0137, grad=0.0000)], [Var(v=-0.1005, grad=0.0000), Var(v=0.0181, grad=0.0000), Var(v=-0.0127, grad=0.0000), Var(v=0.1999, grad=0.0000), Var(v=-0.0897, grad=0.0000), Var(v=-0.0076, grad=0.0000), Var(v=0.0267, grad=0.0000), Var(v=0.1177, grad=0.0000), Var(v=-0.0508, grad=0.0000), Var(v=0.0303, grad=0.0000), Var(v=0.0683, grad=0.0000), Var(v=-0.1520, grad=0.0000), Var(v=0.0177, grad=0.0000), Var(v=0.1819, grad=0.0000), Var(v=0.0069, grad=0.0000), Var(v=0.0539, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=0.0837, grad=0.0000), Var(v=-0.1267, grad=0.0000), Var(v=0.0325, grad=0.0000), Var(v=0.0456, grad=0.0000), Var(v=0.1214, grad=0.0000), Var(v=0.0433, grad=0.0000), Var(v=-0.0056, grad=0.0000), Var(v=-0.0281, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0781, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=0.0877, grad=0.0000), Var(v=-0.1031, grad=0.0000), Var(v=-0.1386, grad=0.0000), Var(v=0.0627, grad=0.0000), Var(v=0.0982, grad=0.0000), Var(v=0.1567, grad=0.0000), Var(v=0.0466, grad=0.0000), Var(v=-0.0339, grad=0.0000), Var(v=-0.0252, grad=0.0000), Var(v=-0.0968, grad=0.0000), Var(v=0.0136, grad=0.0000), Var(v=-0.0310, grad=0.0000), Var(v=0.0200, grad=0.0000), Var(v=0.0476, grad=0.0000), Var(v=-0.0818, grad=0.0000), Var(v=0.0750, grad=0.0000), Var(v=-0.0226, grad=0.0000), Var(v=0.0121, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0067, grad=0.0000), Var(v=-0.0006, grad=0.0000)], [Var(v=-0.0581, grad=0.0000), Var(v=0.1351, grad=0.0000), Var(v=0.0019, grad=0.0000), Var(v=0.1467, grad=0.0000), Var(v=-0.1703, grad=0.0000), Var(v=0.0694, grad=0.0000), Var(v=-0.0722, grad=0.0000), Var(v=0.0755, grad=0.0000), Var(v=0.1026, grad=0.0000), Var(v=-0.0836, grad=0.0000), Var(v=0.0724, grad=0.0000), Var(v=-0.1760, grad=0.0000), Var(v=0.1511, grad=0.0000), Var(v=-0.0570, grad=0.0000), Var(v=0.0858, grad=0.0000), Var(v=0.1266, grad=0.0000), Var(v=0.0130, grad=0.0000), Var(v=-0.1708, grad=0.0000), Var(v=0.0071, grad=0.0000), Var(v=0.1116, grad=0.0000), Var(v=-0.0269, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.1170, grad=0.0000), Var(v=-0.0785, grad=0.0000), Var(v=0.0451, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0238, grad=0.0000), Var(v=0.0191, grad=0.0000), Var(v=-0.0727, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=0.0046, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=-0.1411, grad=0.0000), Var(v=-0.1114, grad=0.0000), Var(v=-0.0273, grad=0.0000), Var(v=0.1794, grad=0.0000), Var(v=0.1429, grad=0.0000), Var(v=0.2494, grad=0.0000), Var(v=0.0980, grad=0.0000), Var(v=-0.1321, grad=0.0000), Var(v=-0.1716, grad=0.0000), Var(v=-0.0970, grad=0.0000), Var(v=-0.1031, grad=0.0000), Var(v=-0.0453, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=0.0500, grad=0.0000), Var(v=0.0073, grad=0.0000), Var(v=-0.1355, grad=0.0000)], [Var(v=0.0377, grad=0.0000), Var(v=0.1245, grad=0.0000), Var(v=0.0014, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=-0.1973, grad=0.0000), Var(v=-0.0286, grad=0.0000), Var(v=-0.1848, grad=0.0000), Var(v=0.0290, grad=0.0000), Var(v=-0.1807, grad=0.0000), Var(v=0.0384, grad=0.0000), Var(v=-0.1705, grad=0.0000), Var(v=-0.1822, grad=0.0000), Var(v=0.1642, grad=0.0000), Var(v=0.0739, grad=0.0000), Var(v=-0.1425, grad=0.0000), Var(v=-0.1681, grad=0.0000), Var(v=-0.0971, grad=0.0000), Var(v=0.0604, grad=0.0000), Var(v=-0.1537, grad=0.0000), Var(v=-0.0924, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=0.0153, grad=0.0000), Var(v=0.0866, grad=0.0000), Var(v=-0.1542, grad=0.0000), Var(v=0.1174, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=-0.0065, grad=0.0000), Var(v=0.0034, grad=0.0000), Var(v=-0.0836, grad=0.0000), Var(v=-0.0334, grad=0.0000), Var(v=-0.0162, grad=0.0000), Var(v=0.2207, grad=0.0000), Var(v=-0.1544, grad=0.0000), Var(v=-0.0044, grad=0.0000), Var(v=0.0104, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0450, grad=0.0000), Var(v=0.2960, grad=0.0000), Var(v=0.0655, grad=0.0000), Var(v=-0.0784, grad=0.0000), Var(v=-0.1599, grad=0.0000), Var(v=0.0050, grad=0.0000), Var(v=-0.0595, grad=0.0000), Var(v=0.0693, grad=0.0000), Var(v=0.1302, grad=0.0000), Var(v=0.1107, grad=0.0000), Var(v=0.0028, grad=0.0000), Var(v=0.0761, grad=0.0000), Var(v=-0.0652, grad=0.0000), Var(v=0.1737, grad=0.0000)], [Var(v=0.0871, grad=0.0000), Var(v=0.1439, grad=0.0000), Var(v=0.1109, grad=0.0000), Var(v=-0.0454, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0280, grad=0.0000), Var(v=0.1577, grad=0.0000), Var(v=0.0216, grad=0.0000), Var(v=0.1322, grad=0.0000), Var(v=-0.0597, grad=0.0000), Var(v=0.1185, grad=0.0000), Var(v=0.1125, grad=0.0000), Var(v=-0.0833, grad=0.0000), Var(v=0.1944, grad=0.0000), Var(v=0.1960, grad=0.0000), Var(v=-0.0903, grad=0.0000), Var(v=-0.0385, grad=0.0000), Var(v=-0.0211, grad=0.0000), Var(v=-0.1800, grad=0.0000), Var(v=0.0013, grad=0.0000), Var(v=-0.0931, grad=0.0000), Var(v=-0.0235, grad=0.0000), Var(v=0.0097, grad=0.0000), Var(v=-0.1651, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0500, grad=0.0000), Var(v=0.0670, grad=0.0000), Var(v=-0.0227, grad=0.0000), Var(v=0.0817, grad=0.0000), Var(v=-0.0644, grad=0.0000), Var(v=0.0834, grad=0.0000), Var(v=0.0577, grad=0.0000), Var(v=-0.1040, grad=0.0000), Var(v=-0.0875, grad=0.0000), Var(v=0.0892, grad=0.0000), Var(v=-0.0046, grad=0.0000), Var(v=-0.1068, grad=0.0000), Var(v=-0.0467, grad=0.0000), Var(v=0.1555, grad=0.0000), Var(v=-0.0837, grad=0.0000), Var(v=0.0815, grad=0.0000), Var(v=0.1532, grad=0.0000), Var(v=-0.1286, grad=0.0000), Var(v=0.0984, grad=0.0000), Var(v=0.0787, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0952, grad=0.0000), Var(v=-0.0116, grad=0.0000)]] Biases: [Var(v=-0.3184, grad=0.0000), Var(v=-0.2710, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.1734, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=0.5842, grad=0.0000), Var(v=-0.2398, grad=0.0000), Var(v=-0.2508, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=1.9913, grad=0.0000), Var(v=-0.0387, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=1.9142, grad=0.0000), Var(v=-0.0214, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0708, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.3127, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-1.9905, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=2.1000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0553, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0161, grad=0.0000), Var(v=-0.0624, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.1940, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.7357, grad=0.0000), Var(v=-0.3556, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.2371, grad=0.0000), Var(v=-0.5430, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.2582, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.1315, grad=0.0000), Var(v=0.7307, grad=0.0000)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=-0.1052, grad=0.0000)], [Var(v=0.1308, grad=0.0000)], [Var(v=0.0642, grad=0.0000)], [Var(v=-0.1283, grad=0.0000)], [Var(v=-0.2168, grad=0.0000)], [Var(v=0.3005, grad=0.0000)], [Var(v=0.0281, grad=0.0000)], [Var(v=-0.0727, grad=0.0000)], [Var(v=-0.0961, grad=0.0000)], [Var(v=0.0782, grad=0.0000)], [Var(v=0.1452, grad=0.0000)], [Var(v=0.1217, grad=0.0000)], [Var(v=-0.0547, grad=0.0000)], [Var(v=-0.1258, grad=0.0000)], [Var(v=-0.0202, grad=0.0000)], [Var(v=0.2573, grad=0.0000)], [Var(v=-0.0296, grad=0.0000)], [Var(v=0.2897, grad=0.0000)], [Var(v=-0.1630, grad=0.0000)], [Var(v=0.0148, grad=0.0000)], [Var(v=0.0060, grad=0.0000)], [Var(v=0.1579, grad=0.0000)], [Var(v=-0.0415, grad=0.0000)], [Var(v=0.1643, grad=0.0000)], [Var(v=0.1547, grad=0.0000)], [Var(v=-0.0425, grad=0.0000)], [Var(v=-0.1739, grad=0.0000)], [Var(v=0.1258, grad=0.0000)], [Var(v=-0.2247, grad=0.0000)], [Var(v=-0.1015, grad=0.0000)], [Var(v=0.0275, grad=0.0000)], [Var(v=0.1176, grad=0.0000)], [Var(v=-0.0141, grad=0.0000)], [Var(v=-0.0151, grad=0.0000)], [Var(v=-0.1154, grad=0.0000)], [Var(v=0.0503, grad=0.0000)], [Var(v=0.0395, grad=0.0000)], [Var(v=-0.0232, grad=0.0000)], [Var(v=0.1099, grad=0.0000)], [Var(v=0.0425, grad=0.0000)], [Var(v=-0.0399, grad=0.0000)], [Var(v=-0.0569, grad=0.0000)], [Var(v=0.0310, grad=0.0000)], [Var(v=0.1351, grad=0.0000)], [Var(v=-0.0064, grad=0.0000)], [Var(v=-0.1731, grad=0.0000)], [Var(v=0.1245, grad=0.0000)], [Var(v=0.0025, grad=0.0000)], [Var(v=-0.1061, grad=0.0000)], [Var(v=0.1327, grad=0.0000)]] Biases: [Var(v=-12.9194, grad=0.0000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Network before update:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
    "\n",
    "def parameters(network):\n",
    "  params = []\n",
    "  for layer in range(len(network)):\n",
    "    params += network[layer].parameters()\n",
    "  return params\n",
    "\n",
    "def update_parameters(params, learning_rate=0.01):\n",
    "  for p in params:\n",
    "    p.v -= learning_rate*p.grad\n",
    "\n",
    "def zero_gradients(params):\n",
    "  for p in params:\n",
    "    p.grad = 0.0\n",
    "\n",
    "update_parameters(parameters(NN))\n",
    "\n",
    "print('\\nNetwork after update:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
    "\n",
    "zero_gradients(parameters(NN))\n",
    "\n",
    "print('\\nNetwork after zeroing gradients:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "woWYpdw6FtIO"
   },
   "outputs": [],
   "source": [
    "# Initialize an arbitrary neural network\n",
    "# NN = [\n",
    "#     DenseLayer(1, 8, lambda x: x.relu()),\n",
    "#     DenseLayer(8, 1, lambda x: x.identity())\n",
    "# ]\n",
    "\n",
    "# Recommended hyper-parameters for 3-D:\n",
    "NN = [\n",
    "   DenseLayer(3, 16, lambda x: x.relu()),\n",
    "   DenseLayer(16, 1, lambda x: x.identity())\n",
    "]\n",
    "\n",
    "\n",
    "### Notice that, when we switch from tanh to relu activation, we decrease the learning rate. This is due the stability of the gradients \n",
    "## of the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mdqaqYBVFtIR"
   },
   "outputs": [],
   "source": [
    "# Initialize training hyperparameters\n",
    "EPOCHS = 200\n",
    "LEARN_R = 2e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kfg76GMFtIW",
    "outputId": "e30cf68a-31f2-42b4-cc5e-860c297c0f04",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 ( 0.00%) Train loss: 102.441 \t Validation loss: 218.812\n",
      "  10 ( 5.00%) Train loss: 6241958632555665558517841920.000 \t Validation loss: 4317500366552420198744074485760.000\n",
      "  20 (10.00%) Train loss: 156471719782764122236953700680201148314331973773326024704.000 \t Validation loss: 108229923856543270924915059313480295193376415627522265317376.000\n",
      "  30 (15.00%) Train loss: 3922390475976826713614461447981605179496267454355682399295039635639850844365814497280.000 \t Validation loss: 2713078268328343320466853416495796433947357945732297487110333153686015544455902080794624.000\n",
      "  40 (20.00%) Train loss: 98325416678445250565963907303532957254878028674299394837236198359700134622547329425205588889517729957570678882304.000 \t Validation loss: 68010707462310770811113321994566878437455496189751667722074307153177643310834459228510520577720320952088395759222784.000\n",
      "  50 (25.00%) Train loss: 2464794778643510292902913317481775760491144437374866490495754444214756304336296142538419460625075722657581159750866005238779288856420063117312.000 \t Validation loss: 1704873900439974080223982541220864876421801190663198102701255067019748778797179839621715598342000252863503723872946295423739607329947632187473920.000\n",
      "  60 (30.00%) Train loss: 61786804531906758375519367412751207074656416020103548526213624824299278434424590357516596457641053403844252622036881542791393387069378655268006378769926805599562258972672.000 \t Validation loss: 42737314826675365923497473848455243790272363742135344537284343346479514575145902684854910513707143781229571506185876601529559966696749406926537143598226626949741076782514176.000\n",
      "  70 (35.00%) Train loss: 1548854796083567434636011377213980609086312415130118989977581555605622180716072260749099523570520678005599904950999988385806418507967485764150710808909927633173070106095583506837763645460900418158592.000 \t Validation loss: 1071327373903020631636012133239219990800090871349001051371773118926486200024722048388226721758931105763978341224233191038700918056525103354173068270813469290607832246399341618515835638968106585776193536.000\n",
      "  80 (40.00%) Train loss: 38826270390988444837300051083855371430313979126082348081949006083198010432914956687451592739282769941577453513585071563845522606053573629490285958794607248420757700203563179511586524377737345394450189393245711743099092898676736.000 \t Validation loss: 26855742966743554553000328975935200517065928897980807080814995803078482371541288823173495809761296908060710628628344801314418222476797916205042237392853403930130477956173488914768535144751048130131311632616461340980450022800752640.000\n",
      "  90 (45.00%) Train loss: 973286376673956368305290863343137971467837467451927083457388981708370837307052598970584838047961799150812503947601559398860766768778784331828032950116353880171230072282008395980080676680153039751409254523980663343698434794664464150068477233367319184408576.000 \t Validation loss: 673212453881628144218019328325739422974963419983786424530379235217655606341646989801727247753454991534689049204374575321823243491933465215131882595053592032720026203175083871475352906702216180764669771668944044878116935210613257729595759447908035172040179712.000\n",
      " 100 (50.00%) Train loss: 24398077937431676442711179544236124159285523826382260880031675757958778182083462288630490212451856586198074697576859065882067346753012562299314971989260691578350976072531452122975239039517592209892387526807983218854576771265957050933481681483115727880348707078418064247489784719605760.000 \t Validation loss: 16875906528542326336819077368449403884289995921793669898662931236254104141192605114508260056303777639696056843309488130673703903879596618445739511860250800091667095042868489782679843033149843283448323639264939736538030150876259140631042084360246832133515298516008988045035014459859402752.000\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOverflowError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [68]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(Loss\u001B[38;5;241m.\u001B[39mv)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Validation\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m Loss_validation \u001B[38;5;241m=\u001B[39m \u001B[43msquared_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_validation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_validation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNN\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m val_loss\u001B[38;5;241m.\u001B[39mappend(Loss_validation\u001B[38;5;241m.\u001B[39mv)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m10\u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36msquared_loss\u001B[1;34m(t, y)\u001B[0m\n\u001B[0;32m     11\u001B[0m Loss \u001B[38;5;241m=\u001B[39m Var(\u001B[38;5;241m0.0\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(t)): \u001B[38;5;66;03m# sum over training data\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m   Loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43msquared_loss_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Loss\n",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36msquared_loss.<locals>.squared_loss_single\u001B[1;34m(t, y)\u001B[0m\n\u001B[0;32m      6\u001B[0m Loss \u001B[38;5;241m=\u001B[39m Var(\u001B[38;5;241m0.0\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(t)): \u001B[38;5;66;03m# sum over outputs\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m   Loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Loss\n",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36mVar.__pow__\u001B[1;34m(self, power)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__pow__\u001B[39m(\u001B[38;5;28mself\u001B[39m, power):\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(power) \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mint\u001B[39m}, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpower must be float or int\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Var(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpower\u001B[49m, \u001B[38;5;28;01mlambda\u001B[39;00m: [(\u001B[38;5;28mself\u001B[39m, power \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m (power \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m))])\n",
      "\u001B[1;31mOverflowError\u001B[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "     \n",
    "    # Forward pass and loss computation\n",
    "    Loss = squared_loss(y_train, forward(x_train, NN))\n",
    "\n",
    "    # Backward pass\n",
    "    Loss.backward()\n",
    "    \n",
    "    # gradient descent update\n",
    "    update_parameters(parameters(NN), LEARN_R)\n",
    "    zero_gradients(parameters(NN))\n",
    "    \n",
    "    # Training loss\n",
    "    train_loss.append(Loss.v)\n",
    "    \n",
    "    # Validation\n",
    "    Loss_validation = squared_loss(y_validation, forward(x_validation, NN))\n",
    "    val_loss.append(Loss_validation.v)\n",
    "    \n",
    "    if e%10==0:\n",
    "        print(\"{:4d}\".format(e),\n",
    "              \"({:5.2f}%)\".format(e/EPOCHS*100), \n",
    "              \"Train loss: {:4.3f} \\t Validation loss: {:4.3f}\".format(train_loss[-1], val_loss[-1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "VetyRWFwFtIY",
    "outputId": "344e490d-6d7d-455a-fa6f-88dd11eb957e"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss);\n",
    "plt.plot(range(len(val_loss)), val_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OgmIrM9FtIb"
   },
   "source": [
    "# Testing\n",
    "\n",
    "We have kept the calculation of the test error separate in order to emphasize that you should not use the test set in optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmNi7S-vFtIc"
   },
   "outputs": [],
   "source": [
    "output_test = forward(x_test, NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "7mmJOTSEFtIf",
    "outputId": "e3264095-cefe-4aee-893d-bf152438e332"
   },
   "outputs": [],
   "source": [
    "y_test_np = Var_to_nparray(y_test)\n",
    "plt.scatter(y_test_np, Var_to_nparray(output_test));\n",
    "plt.plot([np.min(y_test_np), np.max(y_test_np)], [np.min(y_test_np), np.max(y_test_np)], color='k');\n",
    "plt.xlabel(\"y\");\n",
    "plt.ylabel(\"$\\hat{y}$\");\n",
    "plt.title(\"Model prediction vs real in the test set, the close to the line the better\")\n",
    "plt.grid(True);\n",
    "plt.axis('equal');\n",
    "plt.tight_layout();\n",
    "\n",
    "Loss_test = squared_loss(y_test, forward(x_test, NN))\n",
    "\n",
    "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ODi0WlmQFtIh",
    "outputId": "d1ab874f-0717-4987-87bf-1f0c7c8e7148"
   },
   "outputs": [],
   "source": [
    "x_test_np = Var_to_nparray(x_test)\n",
    "x_train_np = Var_to_nparray(x_train)\n",
    "y_train_np = Var_to_nparray(y_train)\n",
    "if D1:\n",
    "    plt.scatter(x_train_np, y_train_np, label=\"train data\");\n",
    "    plt.scatter(x_test_np, Var_to_nparray(output_test), label=\"test prediction\");\n",
    "    plt.scatter(x_test_np, y_test_np, label=\"test data\");\n",
    "    plt.legend();\n",
    "    plt.xlabel(\"x\");\n",
    "    plt.ylabel(\"y\");\n",
    "else:\n",
    "    plt.scatter(x_train_np[:,1], y_train, label=\"train data\");\n",
    "    plt.scatter(x_test_np[:,1], Var_to_nparray(output_test), label=\"test data prediction\");\n",
    "    plt.scatter(x_test_np[:,1], y_test_np, label=\"test data\");\n",
    "    plt.legend();\n",
    "    plt.xlabel(\"x\");\n",
    "    plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTBAmjsAFtIk"
   },
   "source": [
    "## Exercise l) Show overfitting, underfitting and just right fitting\n",
    "\n",
    "Vary the architecture and other things to show clear signs of overfitting (=training loss significantly lower than test loss) and underfitting (=not fitting enoung to training data so that test performance is also hurt).\n",
    "\n",
    "See also if you can get a good compromise which leads to a low validation loss. \n",
    "\n",
    "For this problem do you see any big difference between validation and test loss? The answer here will probably be no. Discuss cases where it is important to keep the two separate.\n",
    "\n",
    "_Insert written answer here._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQZCn2dxFtIl"
   },
   "outputs": [],
   "source": [
    "# Insert your code for getting overfitting, underfitting and just right fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYPZP-eTFtIo"
   },
   "source": [
    "# Next steps - classification\n",
    "\n",
    "It is straight forward to extend what we have done to classification. \n",
    "\n",
    "For numerical stability it is better to make softmax and cross-entropy as one function so we write the cross entropy loss as a function of the logits we talked about last week. \n",
    "\n",
    "Next week we will see how to perform classification in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsVPul3QFtIo"
   },
   "source": [
    "## Exercise m) optional - Implement backpropagation for classification\n",
    "\n",
    "Should be possible with very few lines of code. :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oC8QrI2tFtIp"
   },
   "outputs": [],
   "source": [
    "# Just add code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APqhJv3tta1O"
   },
   "source": [
    "## Exercise n) optional - Introduce a NeuralNetwork class\n",
    "\n",
    "The functions we applied on the neural network (parameters, update_parameters and zero_gradients) can more naturally be included as methods in a NeuralNetwork class. Make such a class and modify the code to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqfnor1ouMLq"
   },
   "outputs": [],
   "source": [
    "# just add some code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "U4057_ljNvWB",
    "p_8n_SKnIW2F",
    "oLrGJytZFtGm",
    "jpIZPBpNI0pO",
    "_79HOAXrFtHK",
    "mqeyab9qFtGs",
    "-XyXBD37FtHk",
    "SrwSJ2UWFtHu",
    "zTBAmjsAFtIk",
    "qsVPul3QFtIo",
    "APqhJv3tta1O"
   ],
   "name": "2.1-EXE-FNN-AutoDif-Nanograd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
